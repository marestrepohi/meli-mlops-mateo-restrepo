# =====================================================================
# DVC Pipeline Configuration
# Data Version Control para MLOps - Housing Price Prediction
# =====================================================================
# Pipeline simplificado de 3 etapas:
# 1. data_ingestion: Descarga de datos desde Kaggle
# 2. data_preparation: Limpieza, splitting y escalado
# 3. model_train: Entrenamiento de 3 experimentos XGBoost con SHAP + MLflow
# =====================================================================

stages:
  # ===================================================================
  # Stage 1: Data Ingestion
  # Descarga datos desde Kaggle, genera dataset limpio y reporte EDA
  # ===================================================================
  data_ingestion:
    cmd: python src/data_ingestion.py
    deps:
      - src/data_ingestion.py
    outs:
      - data/raw/HousingData.csv
      - data/reports/

  # ===================================================================
  # Stage 2: Data Preparation
  # Limpieza, transformaci√≥n y feature engineering
  # GENERA: StandardScaler para producci√≥n (models/production/latest/scaler.pkl)
  # ===================================================================
  data_preparation:
    cmd: python src/data_preparation.py
    deps:
      - src/data_preparation.py
      - data/raw/HousingData.csv
    params:
      - data_ingestion
      - preprocessing
      - data_preparation
    outs:
      - data/processed/
      - models/standard_scaler.pkl
      - models/production/latest/scaler.pkl

  # ===================================================================
  # Stage 3: Model Training
  # Entrenamiento de 3 experimentos XGBoost con SHAP + MLflow
  # üî• USA MLFLOW AUTOLOGGING - Todo se guarda en mlruns/
  # üî• EXPORTA AUTOM√ÅTICAMENTE a models/production/latest/
  # Experimentos:
  #   1. Hyperparameter Tuning (todas las features)
  #   2. Important Features (SHAP percentil 20 + default params)
  #   3. Tuning on Selected Features (features de exp2 + new tuning)
  # Los modelos, artifacts, m√©tricas y par√°metros se guardan autom√°ticamente
  # en mlruns/ gracias a mlflow.xgboost.autolog()
  # El mejor modelo se exporta autom√°ticamente para la API
  # NOTA: El scaler.pkl viene desde data_preparation (no se genera aqu√≠)
  # ===================================================================
  model_train:
    cmd: python src/model_train.py
    deps:
      - src/model_train.py
      - data/processed/train.csv
      - data/processed/test.csv
    params:
      - data_ingestion.target_column
      - preprocessing.processed_data_dir
      - mlflow.tracking_uri
      - mlflow.experiment_name
    outs:
      # Modelo exportado para la API (scaler.pkl viene de data_preparation)
      - models/production/latest/model.pkl
      - models/production/latest/metadata.json

  # ===================================================================
  # Stage 4: Model Registration (OPCIONAL)
  # Registro del mejor modelo en MLflow Model Registry.
  # NOTA: Este stage es opcional. El modelo ya est√° listo en 
  #       models/production/latest/ despu√©s del entrenamiento.
  #       Solo ejecuta esto si necesitas versionado en Model Registry.
  # ===================================================================
  # model_register:
  #   cmd: python src/model_register.py --stage Staging
  #   deps:
  #     - src/model_register.py
  #     - models/model_info.json
