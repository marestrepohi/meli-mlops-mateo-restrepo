# üìã Gu√≠a de Par√°metros - params.yaml

## üìö √çndice

- [Introducci√≥n](#introducci√≥n)
- [Estructura del Archivo](#estructura-del-archivo)
- [Configuraci√≥n por Secci√≥n](#configuraci√≥n-por-secci√≥n)
- [Ejemplos de Uso](#ejemplos-de-uso)
- [Best Practices](#best-practices)

---

## Introducci√≥n

El archivo `params.yaml` centraliza **todos los hiperpar√°metros y configuraciones** del proyecto MLOps, siguiendo las mejores pr√°cticas de la industria. Este enfoque permite:

‚úÖ **Experimentaci√≥n sin modificar c√≥digo**  
‚úÖ **Reproducibilidad completa** de experimentos  
‚úÖ **Tracking autom√°tico** en MLflow  
‚úÖ **Versionado de configuraciones** con Git  
‚úÖ **Colaboraci√≥n eficiente** entre miembros del equipo  

### ¬øPor qu√© params.yaml?

Inspirado en repositorios de referencia como [End-to-end-Youtube-Sentiment](https://github.com/entbappy/End-to-end-Youtube-Sentiment), `params.yaml`:

- Separa configuraci√≥n de c√≥digo
- Facilita A/B testing de hiperpar√°metros
- Permite configuraciones por ambiente (dev/staging/prod)
- Es est√°ndar en pipelines de CI/CD

---

## Estructura del Archivo

```yaml
# params.yaml tiene 15 secciones principales:

1. data_ingestion          # Descarga y split de datos
2. preprocessing           # Limpieza y transformaci√≥n
3. model_building          # Hiperpar√°metros de modelos
4. model_evaluation        # M√©tricas y validaci√≥n
5. mlflow                  # Configuraci√≥n de tracking
6. api                     # Configuraci√≥n del servidor
7. monitoring              # Observabilidad y alertas
8. pipeline                # Automatizaci√≥n del pipeline
9. feature_engineering     # Creaci√≥n de features (experimental)
10. hyperparameter_tuning  # Optimizaci√≥n bayesiana (experimental)
11. reproducibility        # Semillas y determinismo
12. logging                # Configuraci√≥n de logs
13. performance            # Optimizaciones de rendimiento
14. data_validation        # Validaci√≥n de inputs
15. deployment             # Configuraci√≥n de despliegue
```

---

## Configuraci√≥n por Secci√≥n

### 1. Data Ingestion

Controla c√≥mo se descarga y divide el dataset:

```yaml
data_ingestion:
  test_size: 0.2           # 80% train, 20% test
  random_state: 42         # Reproducibilidad
  shuffle: true            # Mezclar antes del split
```

**Cu√°ndo modificar:**
- `test_size`: Para m√°s datos de validaci√≥n (ej: 0.3 = 30%)
- `random_state`: Para diferentes splits (mantener en 42 para reproducibilidad)
- `shuffle`: Poner en `false` si datos tienen orden temporal

### 2. Preprocessing

Define c√≥mo se limpian y transforman los datos:

```yaml
preprocessing:
  scaling_method: "standard"  # standard, minmax, robust
  handle_missing: "drop"      # drop, mean, median, mode
  remove_duplicates: true
  outlier_detection: false    # Experimental
```

**Cu√°ndo modificar:**
- `scaling_method`: 
  - `standard`: Para datos con distribuci√≥n normal (por defecto)
  - `minmax`: Para datos con rango espec√≠fico
  - `robust`: Para datos con outliers
- `handle_missing`: Estrategia para valores faltantes
- `outlier_detection`: Activar para detectar anomal√≠as

### 3. Model Building

**Los hiperpar√°metros m√°s importantes para experimentar:**

#### Random Forest (Recomendado para empezar)

```yaml
random_forest:
  n_estimators: 100        # ‚¨ÜÔ∏è M√°s √°rboles = mejor precisi√≥n (m√°s lento)
  max_depth: 10            # ‚¨ÜÔ∏è Mayor profundidad = m√°s overfitting
  min_samples_split: 2     # ‚¨ÜÔ∏è Mayor valor = menos overfitting
  min_samples_leaf: 1
  max_features: "sqrt"     # sqrt, log2, null (todas)
```

**Consejos de tuning:**
- `n_estimators`: Probar 50, 100, 200, 300
- `max_depth`: Probar 5, 10, 15, 20, null (sin l√≠mite)
- `max_features`: "sqrt" es buen default

#### Gradient Boosting

```yaml
gradient_boosting:
  n_estimators: 100
  learning_rate: 0.1       # ‚¨áÔ∏è Menor = entrenamiento m√°s lento pero mejor
  max_depth: 3             # ‚¨áÔ∏è Menor que RF para evitar overfitting
```

**Consejos de tuning:**
- `learning_rate`: Probar 0.01, 0.05, 0.1, 0.2
- Reducir `learning_rate` y aumentar `n_estimators` suele mejorar

### 4. Model Evaluation

```yaml
model_evaluation:
  metrics:
    - "rmse"               # M√©trica principal
    - "mae"
    - "r2"
  
  generate_plots: true     # ‚¨áÔ∏è Poner false para entrenamientos r√°pidos
  min_r2_score: 0.7        # Alerta si R¬≤ < 0.7
  max_rmse: 10.0           # Alerta si RMSE > 10
```

**Plots generados autom√°ticamente:**
- Prediction vs Actual
- Residuals plot
- Residuals distribution
- Feature importance (si aplica)

### 5. MLflow Configuration

```yaml
mlflow:
  tracking_uri: "http://localhost:5000"
  experiment_name: "housing-price-prediction"
  log_artifacts: true      # Guardar plots y archivos
  log_model: true
  log_plots: true
```

### 6. Monitoring

```yaml
monitoring:
  enabled: true
  drift_detection_enabled: false  # Activar para detectar data drift
  drift_threshold: 0.1
  latency_threshold_ms: 100       # Alerta si > 100ms
```

**Para producci√≥n:**
- Activar `drift_detection_enabled`
- Ajustar `latency_threshold_ms` seg√∫n SLA
- Configurar `error_rate_threshold`

---

## Ejemplos de Uso

### Ejemplo 1: Entrenar con m√°s √°rboles

```yaml
# params.yaml
random_forest:
  n_estimators: 200  # Cambiar de 100 a 200
  max_depth: 10
```

```bash
# Reentrenar
make train

# O manualmente
python src/train.py
```

MLflow autom√°ticamente registrar√° el cambio de `n_estimators: 200`.

### Ejemplo 2: Experimentar con Gradient Boosting m√°s agresivo

```yaml
gradient_boosting:
  n_estimators: 200
  learning_rate: 0.05    # M√°s conservador
  max_depth: 4           # M√°s profundo
```

### Ejemplo 3: Test size diferente

```yaml
data_ingestion:
  test_size: 0.3  # 30% para test (m√°s validaci√≥n)
```

### Ejemplo 4: Cross-validation 10-fold

```yaml
model_building:
  cv_folds: 10  # M√°s robusto pero m√°s lento
```

### Ejemplo 5: Activar detecci√≥n de outliers

```yaml
preprocessing:
  outlier_detection: true
  outlier_method: "iqr"      # Inter-Quartile Range
  outlier_threshold: 1.5
```

---

## Best Practices

### ‚úÖ DO

1. **Versionado con Git**
   ```bash
   git add params.yaml
   git commit -m "feat: increase n_estimators to 200"
   ```

2. **Documentar cambios significativos**
   ```yaml
   # params.yaml
   random_forest:
     n_estimators: 200  # Aumentado de 100 para mejorar R¬≤
   ```

3. **Usar archivos por ambiente**
   ```bash
   params.dev.yaml      # Desarrollo (r√°pido)
   params.staging.yaml  # Pre-producci√≥n
   params.prod.yaml     # Producci√≥n (optimizado)
   ```

4. **Experimentar de forma sistem√°tica**
   ```bash
   # Experimento 1
   vim params.yaml  # n_estimators: 100
   make train

   # Experimento 2
   vim params.yaml  # n_estimators: 200
   make train
   
   # Comparar en MLflow UI
   open http://localhost:5000
   ```

### ‚ùå DON'T

1. **No hardcodear hiperpar√°metros en c√≥digo**
   ```python
   # ‚ùå MAL
   model = RandomForestRegressor(n_estimators=100)
   
   # ‚úÖ BIEN
   params = load_params('params.yaml')
   model = RandomForestRegressor(**params['random_forest'])
   ```

2. **No ignorar warnings de validaci√≥n**
   ```yaml
   model_evaluation:
     min_r2_score: 0.7  # Prestar atenci√≥n si se viola
   ```

3. **No desactivar logging en experimentaci√≥n**
   ```yaml
   mlflow:
     log_artifacts: true  # Mantener true para debug
   ```

---

## Integraci√≥n con el Proyecto

### C√≥mo el C√≥digo Lee params.yaml

```python
# src/train.py

import yaml

# Cargar par√°metros
with open('params.yaml', 'r') as f:
    params = yaml.safe_load(f)

# Usar en entrenamiento
rf_params = params['model_building']['random_forest']
model = RandomForestRegressor(**rf_params)
```

### Tracking Autom√°tico en MLflow

Todos los par√°metros de `params.yaml` se registran autom√°ticamente en MLflow:

```python
# Autom√°tico en src/train.py
mlflow.log_params(params)
```

Ver en MLflow UI: http://localhost:5000

---

## Escenarios Avanzados

### Hyperparameter Tuning con Optuna

```yaml
hyperparameter_tuning:
  enabled: true           # Activar b√∫squeda autom√°tica
  method: "bayesian"      # Optimizaci√≥n bayesiana
  n_trials: 50            # 50 experimentos
  
  rf_search_space:
    n_estimators: [50, 100, 200, 300]
    max_depth: [5, 10, 15, 20, null]
```

```bash
# Ejecutar tuning
python src/hyperparameter_tuning.py  # (Experimental)
```

### Feature Engineering

```yaml
feature_engineering:
  enabled: true
  polynomial_features: true
  poly_degree: 2
  
  interaction_features: true
  interactions:
    - ["RM", "DIS"]       # Rooms x Distance
    - ["LSTAT", "PTRATIO"]
```

---

## Troubleshooting

### Problema: Modelo no mejora

**Soluci√≥n:**
1. Aumentar `n_estimators`
2. Ajustar `learning_rate` (m√°s bajo)
3. Cambiar `max_features`

### Problema: Overfitting (train >> test)

**Soluci√≥n:**
1. Reducir `max_depth`
2. Aumentar `min_samples_split`
3. Activar `cross_validation`

### Problema: Training muy lento

**Soluci√≥n:**
1. Reducir `n_estimators`
2. Reducir `cv_folds`
3. Desactivar `generate_plots` durante experimentaci√≥n

---

## Referencias

- [Documentaci√≥n MLflow](https://mlflow.org/docs/latest/index.html)
- [Scikit-learn Parameters](https://scikit-learn.org/stable/modules/ensemble.html)
- [DVC Pipelines](https://dvc.org/doc/user-guide/pipelines)
- [Repo de Referencia](https://github.com/entbappy/End-to-end-Youtube-Sentiment)

---

## Pr√≥ximos Pasos

1. ‚úÖ Experimentar con diferentes `n_estimators`
2. ‚úÖ Comparar modelos en MLflow UI
3. ‚úÖ Activar cross-validation
4. ‚è≠Ô∏è Implementar hyperparameter tuning (Optuna)
5. ‚è≠Ô∏è Agregar DVC para versionado de datos
6. ‚è≠Ô∏è Configurar environments (dev/staging/prod)

---

**¬øPreguntas?** Consulta el README principal o abre un issue.
