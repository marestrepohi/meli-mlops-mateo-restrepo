# ðŸ  Housing Price Prediction - MLOps Project

[![ML Pipeline CI/CD](https://github.com/marestrepohi/meli-mlops-mateo-restrepo/actions/workflows/ml-pipeline.yml/badge.svg)](https://github.com/marestrepohi/meli-mlops-mateo-restrepo/actions/workflows/ml-pipeline.yml)
[![Python 3.10+](https://img.shields.io/badge/python-3.10+-blue.svg)](https://www.python.org/downloads/)
[![FastAPI](https://img.shields.io/badge/FastAPI-0.104+-green.svg)](https://fastapi.tiangolo.com/)
[![MLflow](https://img.shields.io/badge/MLflow-2.8+-orange.svg)](https://mlflow.org/)

Un sistema completo de MLOps para predecir precios de viviendas utilizando el dataset Boston Housing. Incluye pipeline de entrenamiento reproducible, API REST, monitoreo, containerizaciÃ³n con Docker y CI/CD con GitHub Actions.

## ðŸ“‘ Tabla de Contenidos

- [CaracterÃ­sticas](#-caracterÃ­sticas)
- [Arquitectura](#-arquitectura)
- [Inicio RÃ¡pido](#-inicio-rÃ¡pido)
- [Estructura del Proyecto](#-estructura-del-proyecto)
- [Pipeline de Entrenamiento](#-pipeline-de-entrenamiento)
- [API REST](#-api-rest)
- [Monitoreo](#-monitoreo)
- [Despliegue](#-despliegue)
- [Decisiones TÃ©cnicas](#-decisiones-tÃ©cnicas)
- [Mejoras Futuras](#-mejoras-futuras)
- [Uso de Herramientas AI](#-uso-de-herramientas-ai)

## âœ¨ CaracterÃ­sticas

### ðŸŽ¯ Funcionalidades Core
- **Pipeline de ML Reproducible**: Entrenamiento automatizado con versionado completo
- **ConfiguraciÃ³n Centralizada**: `params.yaml` para hiperparÃ¡metros y configuraciones
- **API REST**: Endpoints para predicciones individuales y en batch
- **Tracking con MLflow**: Seguimiento de experimentos, mÃ©tricas y artefactos visuales
- **Artefactos de EvaluaciÃ³n**: Plots automÃ¡ticos (residuals, feature importance, predictions)
- **Frontend Interactivo**: 6 pÃ¡ginas con visualizaciones completas de todos los procesos MLOps
- **AnÃ¡lisis EDA**: EstadÃ­sticas, distribuciones, correlaciones y feature importance
- **Data Lineage**: Seguimiento de versiones y comparaciÃ³n de datasets
- **Drift Detection**: Monitoreo estadÃ­stico (KS test) con alertas y severidad
- **Datos SintÃ©ticos**: Generador de datos con drift configurable para testing
- **Monitoreo en ProducciÃ³n**: MÃ©tricas de performance, latencia y drift detection
- **ContainerizaciÃ³n**: Docker y docker-compose para despliegue portable
- **CI/CD**: Pipeline automatizado con GitHub Actions
- **Testing**: Suite de tests unitarios e integraciÃ³n

### ðŸ”§ Stack TecnolÃ³gico

**Backend:**
- **ML Framework**: scikit-learn
- **API**: FastAPI + Uvicorn
- **Tracking**: MLflow (open-source)
- **Analytics**: scipy, matplotlib, seaborn
- **ContainerizaciÃ³n**: Docker + docker-compose
- **Testing**: pytest
- **CI/CD**: GitHub Actions

**Frontend:**
- **Framework**: React 18 + TypeScript
- **Build Tool**: Vite
- **UI**: shadcn/ui + Radix UI + Tailwind CSS
- **Charts**: Recharts
- **HTTP Client**: Axios
- **State**: TanStack Query (React Query)
- **Routing**: React Router v6

## ðŸ— Arquitectura

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    GitHub Actions CI/CD                     â”‚
â”‚              (Testing, Linting, Building, Deploy)           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                      â”‚
                      â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                   Training Pipeline                         â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”             â”‚
â”‚  â”‚   Data     â”‚â†’ â”‚Preprocess  â”‚â†’ â”‚  Train   â”‚             â”‚
â”‚  â”‚  Download  â”‚  â”‚  & Split   â”‚  â”‚ Multiple â”‚             â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚  Models  â”‚             â”‚
â”‚                                   â””â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜             â”‚
â”‚                                         â†“                   â”‚
â”‚                  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”‚
â”‚                  â”‚      MLflow Tracking Server      â”‚      â”‚
â”‚                  â”‚  â€¢ Experiments  â€¢ Metrics        â”‚      â”‚
â”‚                  â”‚  â€¢ Parameters   â€¢ Artifacts      â”‚      â”‚
â”‚                  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                   â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                   Production API (FastAPI)                  â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”‚
â”‚  â”‚  /predict    â”‚  â”‚   /health    â”‚  â”‚   /metrics   â”‚     â”‚
â”‚  â”‚  /batch      â”‚  â”‚  /model/info â”‚  â”‚ /admin/reloadâ”‚     â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â”‚
â”‚                                                             â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”‚
â”‚  â”‚            Model Monitor                         â”‚     â”‚
â”‚  â”‚  â€¢ Latency tracking  â€¢ Prediction logging        â”‚     â”‚
â”‚  â”‚  â€¢ Data drift        â€¢ Performance metrics       â”‚     â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ðŸš€ Inicio RÃ¡pido

### Pre-requisitos

- Python 3.10+
- Credenciales de Kaggle (para descargar dataset)

### OpciÃ³n 1: Desarrollo Local

```bash
# 1. Crear entorno virtual
python3 -m venv venv
source venv/bin/activate  # En Windows: venv\Scripts\activate

# 2. Instalar dependencias
pip install --upgrade pip
pip install -r requirements.txt
pip install -e .

# 3. Configurar credenciales de Kaggle
cp .env.example .env
# Editar .env y agregar tus credenciales:
# KAGGLE_USERNAME=tu_usuario
# KAGGLE_KEY=tu_api_key

# 4. Crear directorios necesarios
mkdir -p data/{raw,processed,reports} models logs

# 5. Ejecutar pipeline de entrenamiento con DVC
dvc repro

# 6. Iniciar MLflow UI (en otra terminal)
mlflow ui --host 0.0.0.0 --port 5000

# 7. Iniciar API
python src/main.py
# O con uvicorn:
uvicorn src.main:app --host 0.0.0.0 --port 8000 --reload

# Acceder a:
# - API Docs: http://localhost:8000/docs
# - MLflow UI: http://localhost:5000
```

### OpciÃ³n 2: Docker (Recomendado para producciÃ³n)

```bash
# Construir y levantar servicios
docker-compose up --build

# Acceder a:
# - API: http://localhost:8000/docs
# - MLflow: http://localhost:5000

# Detener servicios
docker-compose down
```

### ðŸ“ Probar la API

```bash
# Health check
curl http://localhost:8000/health

# PredicciÃ³n individual
curl -X POST "http://localhost:8000/predict" \
  -H "Content-Type: application/json" \
  -d '{
    "CRIM": 0.00632,
    "ZN": 18.0,
    "INDUS": 2.31,
    "CHAS": 0.0,
    "NOX": 0.538,
    "RM": 6.575,
    "AGE": 65.2,
    "DIS": 4.0900,
    "RAD": 1.0,
    "TAX": 296.0,
    "PTRATIO": 15.3,
    "B": 396.90,
    "LSTAT": 4.98
  }'

# MÃ©tricas
curl http://localhost:8000/metrics

# TambiÃ©n puedes usar Swagger UI: http://localhost:8000/docs
```

## ðŸ”„ Pipeline de Entrenamiento con DVC

### Ejecutar Pipeline Completo

```bash
# Ejecutar todas las etapas del pipeline
dvc repro

# Ver estado del pipeline
dvc status

# Ver mÃ©tricas
dvc metrics show

# Ver DAG del pipeline
dvc dag

# Comparar experimentos
dvc metrics diff
```

### Ejecutar Etapas Individuales

```bash
# Solo descarga de datos
dvc repro data_ingestion

# Solo preprocesamiento
dvc repro preprocess

# Solo entrenamiento baseline
dvc repro train_baseline

# Solo modelo final
dvc repro train_final
```

### Ver Resultados en MLflow

```bash
# Iniciar MLflow UI
mlflow ui --host 0.0.0.0 --port 5000

# Acceder a: http://localhost:5000
# AquÃ­ puedes:
# - Comparar experimentos
# - Ver mÃ©tricas (RMSE, MAE, RÂ²)
# - Descargar artefactos (plots, modelos)
# - Revisar hiperparÃ¡metros
```

### Reentrenar con Nuevos ParÃ¡metros

```bash
# 1. Editar params.yaml
# Ejemplo: Cambiar max_depth de 6 a 10
nano params.yaml

# 2. Ejecutar pipeline (DVC detecta cambios automÃ¡ticamente)
dvc repro

# 3. Ver comparaciÃ³n con experimento anterior
dvc metrics diff
mlflow ui  # Comparar visualmente en la UI
```

## ðŸ“ Estructura del Proyecto

```
.
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ config.py              # ConfiguraciÃ³n centralizada
â”‚   â”œâ”€â”€ data_ingestion.py      # Descarga e ingesta de datos (DVC stage 1)
â”‚   â”œâ”€â”€ data_preparation.py    # Preprocesamiento y feature engineering
â”‚   â”œâ”€â”€ train.py               # Pipeline de entrenamiento XGBoost
â”‚   â”œâ”€â”€ evaluate.py            # EvaluaciÃ³n y comparaciÃ³n de modelos
â”‚   â”œâ”€â”€ register_model.py      # Registro en MLflow Model Registry
â”‚   â”œâ”€â”€ main.py                # API FastAPI
â”‚   â”œâ”€â”€ monitoring.py          # Sistema de monitoreo
â”‚   â””â”€â”€ analytics.py           # Endpoints de analytics
â”œâ”€â”€ data/                      # Datasets (generado por pipeline, en .gitignore)
â”‚   â”œâ”€â”€ raw/                   # Datos crudos descargados
â”‚   â”œâ”€â”€ processed/             # Datos procesados (train.csv, test.csv)
â”‚   â””â”€â”€ reports/               # Reportes EDA
â”œâ”€â”€ models/                    # Modelos entrenados (en .gitignore)
â”‚   â”œâ”€â”€ xgboost_baseline.pkl
â”‚   â”œâ”€â”€ xgboost_tuned.pkl
â”‚   â”œâ”€â”€ xgboost_final.pkl
â”‚   â”œâ”€â”€ evaluation/            # Reportes de evaluaciÃ³n
â”‚   â””â”€â”€ production/            # Modelo en producciÃ³n
â”œâ”€â”€ mlruns/                    # MLflow tracking data (en .gitignore)
â”œâ”€â”€ logs/                      # Logs de predicciones (en .gitignore)
â”œâ”€â”€ front/                     # Frontend React (opcional)
â”œâ”€â”€ notebooks/                 # Jupyter notebooks para exploraciÃ³n
â”œâ”€â”€ tests/                     # Tests unitarios e integraciÃ³n
â”œâ”€â”€ .github/workflows/         # CI/CD con GitHub Actions
â”œâ”€â”€ dvc.yaml                   # DefiniciÃ³n del pipeline DVC
â”œâ”€â”€ params.yaml                # HiperparÃ¡metros y configuraciÃ³n
â”œâ”€â”€ requirements.txt           # Dependencias Python
â”œâ”€â”€ docker-compose.yml         # OrquestaciÃ³n de servicios
â”œâ”€â”€ Dockerfile                 # Imagen Docker para la API
â””â”€â”€ README.md                  # Este archivo
```

## ðŸ”¬ Pipeline de Entrenamiento

### Etapas del Pipeline DVC

El pipeline estÃ¡ definido en `dvc.yaml` y consta de 8 etapas:

1. **data_ingestion**: Descarga dataset desde Kaggle
2. **preprocess**: Limpieza, transformaciÃ³n y split train/test
3. **train_baseline**: XGBoost baseline con todas las features
4. **train_tuned**: Hyperparameter tuning con GridSearchCV
5. **feature_selection**: SelecciÃ³n de top features por importancia
6. **train_final**: Modelo final con features seleccionadas
7. **evaluate**: ComparaciÃ³n de todos los modelos
8. **register_model**: Registro del mejor modelo en MLflow

### Componentes

**Data Ingestion** (`data_ingestion.py`)
- Descarga automÃ¡tica desde Kaggle usando API oficial
- ValidaciÃ³n de datos (missing values, tipos, estadÃ­sticas)
- GeneraciÃ³n de reporte EDA con `ydata-profiling`
- ConfiguraciÃ³n de credenciales desde .env

**Preprocessing** (`data_preparation.py`)
- Limpieza de datos (missing values, duplicados)
- IdentificaciÃ³n automÃ¡tica de features y target
- Split train/test configurable desde `params.yaml`
- StandardizaciÃ³n con `StandardScaler`
- Persistencia del preprocessor para inferencia

**Training** (`train.py`)
- MÃºltiples estrategias de XGBoost:
  - Baseline con todas las features
  - Hyperparameter tuning con GridSearchCV
  - Feature selection por importancia
  - Modelo final optimizado
- Tracking automÃ¡tico con MLflow:
  - ParÃ¡metros (todos los hiperparÃ¡metros)
  - MÃ©tricas (RMSE, MAE, RÂ², MSE)
  - Artefactos (plots de evaluaciÃ³n, modelo, preprocessor)
- GeneraciÃ³n de plots automÃ¡ticos:
  - Predictions vs Actual
  - Residuals plot
  - Residuals distribution
  - Feature importance (top 15)

**Evaluation** (`evaluate.py`)
- ComparaciÃ³n de todos los modelos entrenados
- GeneraciÃ³n de reportes HTML
- MÃ©tricas detalladas para cada modelo

**Model Registration** (`register_model.py`)
- Registro del mejor modelo en MLflow Model Registry
- Versionado automÃ¡tico
- Metadatos del modelo

### MÃ©tricas Evaluadas

- **RMSE**: Root Mean Squared Error (penaliza outliers)
- **MAE**: Mean Absolute Error (interpretable en unidades originales)
- **RÂ²**: Coeficiente de determinaciÃ³n (0-1, mayor es mejor)
- **MSE**: Mean Squared Error

### Reproducibilidad

- Seeds fijos (`random_state=42`)
- Versionado de cÃ³digo con Git
- Versionado de datos con DVC
- Tracking completo con MLflow
- ConfiguraciÃ³n centralizada en `params.yaml`

### ConfiguraciÃ³n con params.yaml

El archivo `params.yaml` centraliza todos los hiperparÃ¡metros y configuraciones:

```yaml
# Ejemplo: Configurar XGBoost baseline
model_building:
  xgboost_baseline:
    n_estimators: 100
    max_depth: 6
    learning_rate: 0.1
    subsample: 0.8
    colsample_bytree: 0.8

# Configurar preprocessing
preprocessing:
  scaling_method: "standard"
  handle_missing: "drop"
  remove_duplicates: true

# Configurar data split
data_ingestion:
  test_size: 0.2
  random_state: 42
  shuffle: true
```

**Beneficios:**
- âœ… ExperimentaciÃ³n sin modificar cÃ³digo
- âœ… Versionado de configuraciones con Git
- âœ… Tracking automÃ¡tico en MLflow
- âœ… ColaboraciÃ³n simplificada

## ðŸŒ API REST

### Endpoints Principales

#### `POST /predict`
PredicciÃ³n individual de precio de vivienda.

**Request:**
```json
{
  "CRIM": 0.00632,
  "ZN": 18.0,
  "INDUS": 2.31,
  "CHAS": 0.0,
  "NOX": 0.538,
  "RM": 6.575,
  "AGE": 65.2,
  "DIS": 4.0900,
  "RAD": 1.0,
  "TAX": 296.0,
  "PTRATIO": 15.3,
  "B": 396.90,
  "LSTAT": 4.98
}
```

**Response:**
```json
{
  "prediction": 30.12,
  "model_version": "1.0.0",
  "inference_time": 0.0023
}
```

#### `POST /predict/batch`
Predicciones en batch para mÃºltiples entradas.

#### `GET /health`
Health check del servicio.

**Response:**
```json
{
  "status": "healthy",
  "model_loaded": true,
  "uptime_hours": 2.5,
  "total_predictions": 157,
  "warnings": []
}
```

#### `GET /metrics`
MÃ©tricas de monitoreo.

**Response:**
```json
{
  "total_predictions": 157,
  "avg_inference_time": 0.0024,
  "p95_inference_time": 0.0035,
  "avg_prediction": 22.5,
  "std_prediction": 9.2,
  "uptime_hours": 2.5
}
```

#### `GET /model/info`
InformaciÃ³n del modelo en producciÃ³n.

#### `POST /admin/reload`
Recargar modelo sin reiniciar el servicio.

### DocumentaciÃ³n Interactiva

- **Swagger UI**: http://localhost:8000/docs
- **ReDoc**: http://localhost:8000/redoc

## ðŸ“Š Monitoreo

### Sistema de Monitoreo (`monitoring.py`)

El sistema incluye monitoreo comprehensivo en producciÃ³n:

#### 1. **MÃ©tricas de Performance**
- Latencia de inferencia (avg, p50, p95, p99)
- Throughput (predicciones/hora)
- Uptime del servicio

#### 2. **Logging de Predicciones**
- Todas las predicciones se registran con:
  - Timestamp
  - Features de entrada
  - PredicciÃ³n
  - Tiempo de inferencia
- Guardado periÃ³dico en `/logs/`

#### 3. **Data Drift Detection**
- ComparaciÃ³n de estadÃ­sticas de features vs baseline
- Alerta si mean se desvÃ­a > 2 std
- Ãštil para detectar cambios en distribuciÃ³n de datos

#### 4. **Health Checks**
- VerificaciÃ³n de estado del modelo
- DetecciÃ³n de anomalÃ­as (ej. alta latencia)
- Status: `healthy`, `degraded`, `warning`

### Ejemplo de Uso

```python
from monitoring import monitor

# El monitor se actualiza automÃ¡ticamente con cada predicciÃ³n
metrics = monitor.get_metrics()
health = monitor.get_health_status()
drift = monitor.detect_drift(baseline_stats)
```

## ðŸ”§ Troubleshooting

### Error: "dvc: command not found"
```bash
pip install dvc
```

### Error: "Kaggle credentials not found"
```bash
# Crear archivo .env con credenciales
cp .env.example .env
# Editar y agregar:
# KAGGLE_USERNAME=tu_usuario
# KAGGLE_KEY=tu_api_key
```

Para obtener tu API key de Kaggle:
1. Ve a https://www.kaggle.com/settings/account
2. En "API" section, click "Create New API Token"
3. Se descargarÃ¡ `kaggle.json` con tus credenciales

### Error: "Model not loaded" en la API
```bash
# AsegÃºrate de que el pipeline haya terminado exitosamente
ls -la models/production/

# Debe contener:
# - model.joblib
# - preprocessor.joblib
# - metrics.json

# Si no existe, ejecuta:
dvc repro
```

### Error: "MLflow tracking URI not accessible"
```bash
# Verifica que MLflow estÃ© corriendo
mlflow ui --host 0.0.0.0 --port 5000

# O cambia a file-based tracking en .env:
# MLFLOW_TRACKING_URI=./mlruns
```

### El pipeline DVC no detecta cambios
```bash
# Forzar re-ejecuciÃ³n de una etapa
dvc repro --force train_baseline

# Ver quÃ© cambiÃ³
dvc status

# Limpiar cachÃ©
dvc gc
```

### Problemas de memoria durante entrenamiento
```bash
# Reducir n_estimators en params.yaml
# O usar menos datos para pruebas rÃ¡pidas
```

## ðŸ›  Comandos Ãštiles

```bash
# Ver mÃ©tricas de todos los experimentos
dvc metrics show

# Comparar con experimento anterior
dvc metrics diff HEAD~1

# Ver grÃ¡fica del pipeline
dvc dag

# Verificar quÃ© cambiÃ³ en el pipeline
dvc status

# Limpiar outputs del pipeline
dvc remove dvc.yaml

# Re-ejecutar todo desde cero
rm -rf models/ data/processed/ data/reports/
dvc repro

# Ver logs de MLflow
cat mlruns/*/meta.yaml

# Verificar salud de la API
curl http://localhost:8000/health | jq

# Ver mÃ©tricas de la API
curl http://localhost:8000/metrics | jq

# Test rÃ¡pido de predicciÃ³n
curl -X POST http://localhost:8000/predict \
  -H "Content-Type: application/json" \
  -d @tests/sample_input.json
```

### Docker Compose

El proyecto incluye `docker-compose.yml` con dos servicios:

1. **MLflow Server** (Puerto 5000)
   - Tracking server
   - Backend: file system
   - Artifacts: local storage

2. **API Service** (Puerto 8000)
   - FastAPI application
   - Auto-reload en desarrollo
   - Health checks configurados

```bash
# Desarrollo
docker-compose up

# ProducciÃ³n (detached)
docker-compose up -d

# Ver logs
docker-compose logs -f api

# Escalar API
docker-compose up --scale api=3
```

### Kubernetes (Ejemplo)

```yaml
# deployment.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: housing-api
spec:
  replicas: 3
  selector:
    matchLabels:
      app: housing-api
  template:
    metadata:
      labels:
        app: housing-api
    spec:
      containers:
      - name: api
        image: housing-price-api:latest
        ports:
        - containerPort: 8000
        env:
        - name: MLFLOW_TRACKING_URI
          value: "http://mlflow-service:5000"
        livenessProbe:
          httpGet:
            path: /health
            port: 8000
          initialDelaySeconds: 30
          periodSeconds: 10
        resources:
          requests:
            memory: "512Mi"
            cpu: "500m"
          limits:
            memory: "1Gi"
            cpu: "1000m"
```

## ðŸ’¡ Decisiones TÃ©cnicas

### 1. **Stack AgnÃ³stico Cloud**
**DecisiÃ³n**: Usar solo herramientas open-source (MLflow, FastAPI, Docker)

**JustificaciÃ³n**:
- âœ… Portabilidad total entre proveedores
- âœ… Sin vendor lock-in
- âœ… Control completo del stack
- âœ… Costos predecibles
- âŒ Menos features managed (auto-scaling, managed infra)

**Alternativas consideradas**: AWS SageMaker, Google AI Platform, Azure ML

### 2. **MLflow para Experiment Tracking**
**DecisiÃ³n**: MLflow open-source con backend de archivos

**JustificaciÃ³n**:
- âœ… Industry standard
- âœ… UI integrada para visualizaciÃ³n
- âœ… Versionado de modelos
- âœ… FÃ¡cil migraciÃ³n a backends robustos (PostgreSQL, S3)
- âœ… API Python simple

**Alternativas consideradas**: Weights & Biases, Neptune.ai, DVC

### 3. **FastAPI como Framework Web**
**DecisiÃ³n**: FastAPI sobre Flask/Django

**JustificaciÃ³n**:
- âœ… Performance superior (async/await)
- âœ… ValidaciÃ³n automÃ¡tica con Pydantic
- âœ… DocumentaciÃ³n auto-generada (OpenAPI/Swagger)
- âœ… Type hints nativos
- âœ… DiseÃ±ado para APIs modernas

**Benchmarks**: ~3x mÃ¡s rÃ¡pido que Flask en I/O bound tasks

### 4. **MÃºltiples Modelos con SelecciÃ³n AutomÃ¡tica**
**DecisiÃ³n**: Entrenar 4 modelos y seleccionar el mejor por RMSE

**JustificaciÃ³n**:
- âœ… ValidaciÃ³n de que modelo simple no es suficiente
- âœ… ComparaciÃ³n justa con mismos datos
- âœ… Random Forest ganÃ³ consistentemente (mejor bias-variance tradeoff)
- âœ… Tracking de todos los experimentos

**Modelos probados**:
1. Linear Regression (baseline)
2. Ridge (regularizaciÃ³n L2)
3. Random Forest (ensemble, no lineal)
4. Gradient Boosting (ensemble secuencial)

### 5. **Monitoreo In-Process**
**DecisiÃ³n**: Monitoreo dentro del proceso de la API

**JustificaciÃ³n**:
- âœ… Simplicidad (no requiere infra adicional)
- âœ… Suficiente para MVP
- âœ… FÃ¡cil evoluciÃ³n a Prometheus/Grafana
- âŒ No persistente entre reinicios

**Mejora futura**: Exportar a Prometheus + Grafana

### 6. **StandardScaler vs Min-Max**
**DecisiÃ³n**: StandardScaler para normalizaciÃ³n

**JustificaciÃ³n**:
- âœ… No asume rango fijo [0,1]
- âœ… Robusto a outliers
- âœ… Funciona bien con modelos lineales y tree-based
- âœ… Preserva estructura de outliers

### 7. **Estructura Modular**
**DecisiÃ³n**: SeparaciÃ³n clara de concerns

**JustificaciÃ³n**:
- âœ… Testeable independientemente
- âœ… Reutilizable (preprocessing en train e inference)
- âœ… Extensible (fÃ¡cil agregar nuevos modelos)
- âœ… Mantenible

```
config.py          â†’ ConfiguraciÃ³n centralizada
preprocessing.py   â†’ LÃ³gica de datos
train.py          â†’ Pipeline de entrenamiento
main.py           â†’ API
monitoring.py     â†’ Observabilidad
```

## ðŸš€ Mejoras Futuras

### Corto Plazo (1-2 sprints)

1. **Feature Engineering**
   - Interacciones entre features (RM * DIS)
   - Transformaciones no lineales (log, sqrt)
   - Binning de variables continuas

2. **Hyperparameter Tuning**
   - Grid Search o Random Search
   - Optuna para optimizaciÃ³n bayesiana
   - ValidaciÃ³n cruzada k-fold

3. **Model Validation**
   - Cross-validation en entrenamiento
   - AnÃ¡lisis de residuos
   - Feature importance

4. **Testing Mejorado**
   - Tests de integraciÃ³n end-to-end
   - Tests de carga (locust)
   - Contract testing para API

### Medio Plazo (3-6 meses)

5. **Monitoreo Avanzado**
   - IntegraciÃ³n con Prometheus + Grafana
   - Alertas automÃ¡ticas (PagerDuty, Slack)
   - Dashboards de mÃ©tricas de negocio

6. **Data Drift Detection Robusto**
   - Kolmogorov-Smirnov test
   - Population Stability Index (PSI)
   - Reentrenamiento automÃ¡tico si drift > threshold

7. **A/B Testing**
   - Framework para probar modelos nuevos
   - Traffic splitting
   - MÃ©tricas de negocio

8. **Model Registry**
   - Versionado de modelos con MLflow Registry
   - Staging â†’ Production promotion
   - Rollback automÃ¡tico

### Largo Plazo (6-12 meses)

9. **Feature Store**
   - Feast o Tecton
   - Features compartidas entre modelos
   - Consistencia train/serve

10. **Advanced Deployment**
    - Blue-green deployment
    - Canary releases
    - Shadow mode

11. **AutoML**
    - Auto-sklearn o H2O AutoML
    - ExploraciÃ³n automÃ¡tica de modelos
    - Feature engineering automÃ¡tico

12. **Seguridad**
    - AutenticaciÃ³n API (OAuth2, API keys)
    - Rate limiting
    - Input validation mÃ¡s estricta
    - EncriptaciÃ³n de datos sensibles

13. **Escalabilidad**
    - Kubernetes con HPA
    - Cache de predicciones (Redis)
    - Batch inference optimizado
    - GPU para modelos complejos

14. **Compliance & Governance**
    - Lineage de datos
    - Explicabilidad (SHAP, LIME)
    - Audit logs
    - GDPR compliance

## ðŸ¤– Uso de Herramientas AI

Este proyecto fue desarrollado con asistencia de **GitHub Copilot** y **GPT-4** en las siguientes Ã¡reas:

### Copilot (Inline suggestions)
- âœ… Autocompletado de funciones repetitivas
- âœ… GeneraciÃ³n de docstrings
- âœ… Sugerencias de tipo hints
- âœ… Patrones de cÃ³digo comunes

### GPT-4 (Chat-based)
- âœ… DiseÃ±o de arquitectura MLOps
- âœ… RevisiÃ³n de decisiones tÃ©cnicas
- âœ… GeneraciÃ³n de tests unitarios
- âœ… Escritura de documentaciÃ³n
- âœ… Troubleshooting de errores

### CÃ³digo Escrito Manualmente
- âœ… LÃ³gica de negocio core (preprocessing, training)
- âœ… ConfiguraciÃ³n de MLflow
- âœ… DiseÃ±o de API endpoints
- âœ… IntegraciÃ³n de componentes

### ValidaciÃ³n
- âœ… Todo el cÃ³digo fue revisado manualmente
- âœ… Tests ejecutados y pasando
- âœ… Best practices validadas
- âœ… Security considerations aplicadas

**Nota**: Las herramientas AI aceleraron el desarrollo ~30-40%, especialmente en tareas repetitivas y documentaciÃ³n.

## ðŸ“š Referencias

- [MLflow Documentation](https://mlflow.org/docs/latest/index.html)
- [FastAPI Documentation](https://fastapi.tiangolo.com/)
- [scikit-learn Documentation](https://scikit-learn.org/)
- [Boston Housing Dataset](https://www.kaggle.com/datasets/altavish/boston-housing-dataset)
- [MLOps Best Practices](https://ml-ops.org/)
- [Google MLOps Principles](https://cloud.google.com/architecture/mlops-continuous-delivery-and-automation-pipelines-in-machine-learning)

## ðŸ‘¤ Autor

**Mateo Restrepo**
- GitHub: [@marestrepohi](https://github.com/marestrepohi)
- Proyecto: Prueba TÃ©cnica MLOps - MercadoLibre

## ðŸ“„ Licencia

Este proyecto es para fines educativos y de evaluaciÃ³n tÃ©cnica.

---

**Â¿Preguntas?** Abre un issue o contacta al autor.

**Para la presentaciÃ³n**: Revisar secciones de Arquitectura, Decisiones TÃ©cnicas y Mejoras Futuras. ðŸš€
