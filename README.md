# ðŸ  Housing Price Prediction - MLOps Project

[![ML Pipeline CI/CD](https://github.com/marestrepohi/meli-mlops-mateo-restrepo/actions/workflows/ml-pipeline.yml/badge.svg)](https://github.com/marestrepohi/meli-mlops-mateo-restrepo/actions/workflows/ml-pipeline.yml)
[![Python 3.10+](https://img.shields.io/badge/python-3.10+-blue.svg)](https://www.python.org/downloads/)
[![FastAPI](https://img.shields.io/badge/FastAPI-0.104+-green.svg)](https://fastapi.tiangolo.com/)
[![MLflow](https://img.shields.io/badge/MLflow-2.8+-orange.svg)](https://mlflow.org/)

Un sistema completo de MLOps para predecir precios de viviendas utilizando el dataset Boston Housing. Incluye pipeline de entrenamiento reproducible, API REST, monitoreo, containerizaciÃ³n con Docker y CI/CD con GitHub Actions.

## ðŸ“‘ Tabla de Contenidos

- [CaracterÃ­sticas](#-caracterÃ­sticas)
- [Arquitectura](#-arquitectura)
- [Inicio RÃ¡pido](#-inicio-rÃ¡pido)
- [Estructura del Proyecto](#-estructura-del-proyecto)
- [Pipeline de Entrenamiento](#-pipeline-de-entrenamiento)
- [API REST](#-api-rest)
- [Monitoreo](#-monitoreo)
- [Despliegue](#-despliegue)
- [Decisiones TÃ©cnicas](#-decisiones-tÃ©cnicas)
- [Mejoras Futuras](#-mejoras-futuras)
- [Uso de Herramientas AI](#-uso-de-herramientas-ai)

## âœ¨ CaracterÃ­sticas

### ðŸŽ¯ Funcionalidades Core
- **Pipeline de ML Reproducible**: Entrenamiento automatizado con versionado completo
- **ConfiguraciÃ³n Centralizada**: `params.yaml` para hiperparÃ¡metros y configuraciones
- **API REST**: Endpoints para predicciones individuales y en batch
- **Tracking con MLflow**: Seguimiento de experimentos, mÃ©tricas y artefactos visuales
- **Artefactos de EvaluaciÃ³n**: Plots automÃ¡ticos (residuals, feature importance, predictions)
- **Monitoreo en ProducciÃ³n**: MÃ©tricas de performance, latencia y drift detection
- **ContainerizaciÃ³n**: Docker y docker-compose para despliegue portable
- **CI/CD**: Pipeline automatizado con GitHub Actions
- **Testing**: Suite de tests unitarios e integraciÃ³n

### ðŸ”§ Stack TecnolÃ³gico
- **ML Framework**: scikit-learn
- **API**: FastAPI + Uvicorn
- **Tracking**: MLflow (open-source)
- **ContainerizaciÃ³n**: Docker + docker-compose
- **Testing**: pytest
- **CI/CD**: GitHub Actions
- **Monitoring**: Custom metrics + Prometheus-ready

## ðŸ— Arquitectura

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    GitHub Actions CI/CD                     â”‚
â”‚              (Testing, Linting, Building, Deploy)           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                      â”‚
                      â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                   Training Pipeline                         â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”             â”‚
â”‚  â”‚   Data     â”‚â†’ â”‚Preprocess  â”‚â†’ â”‚  Train   â”‚             â”‚
â”‚  â”‚  Download  â”‚  â”‚  & Split   â”‚  â”‚ Multiple â”‚             â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚  Models  â”‚             â”‚
â”‚                                   â””â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜             â”‚
â”‚                                         â†“                   â”‚
â”‚                  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”‚
â”‚                  â”‚      MLflow Tracking Server      â”‚      â”‚
â”‚                  â”‚  â€¢ Experiments  â€¢ Metrics        â”‚      â”‚
â”‚                  â”‚  â€¢ Parameters   â€¢ Artifacts      â”‚      â”‚
â”‚                  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                   â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                   Production API (FastAPI)                  â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”‚
â”‚  â”‚  /predict    â”‚  â”‚   /health    â”‚  â”‚   /metrics   â”‚     â”‚
â”‚  â”‚  /batch      â”‚  â”‚  /model/info â”‚  â”‚ /admin/reloadâ”‚     â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â”‚
â”‚                                                             â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”‚
â”‚  â”‚            Model Monitor                         â”‚     â”‚
â”‚  â”‚  â€¢ Latency tracking  â€¢ Prediction logging        â”‚     â”‚
â”‚  â”‚  â€¢ Data drift        â€¢ Performance metrics       â”‚     â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ðŸš€ Inicio RÃ¡pido

### OpciÃ³n 1: Docker (Recomendado)

```bash


# Construir y levantar servicios
docker-compose up --build

# Acceder a:
# - API: http://localhost:8000/docs
# - MLflow: http://localhost:5000
```

### OpciÃ³n 2: Local

```bash


# Setup inicial
chmod +x setup.sh train.sh run_api.sh
./setup.sh

# Activar entorno virtual
source venv/bin/activate

# Descargar datos
python src/download_data.py

# Entrenar modelo
./train.sh

# Iniciar API
./run_api.sh
```

### ðŸ“ Probar la API

```bash
# Health check
curl http://localhost:8000/health

# PredicciÃ³n individual
curl -X POST "http://localhost:8000/predict" \
  -H "Content-Type: application/json" \
  -d '{
    "CRIM": 0.00632,
    "ZN": 18.0,
    "INDUS": 2.31,
    "CHAS": 0.0,
    "NOX": 0.538,
    "RM": 6.575,
    "AGE": 65.2,
    "DIS": 4.0900,
    "RAD": 1.0,
    "TAX": 296.0,
    "PTRATIO": 15.3,
    "B": 396.90,
    "LSTAT": 4.98
  }'

# MÃ©tricas
curl http://localhost:8000/metrics
```

## ðŸ“ Estructura del Proyecto

```
server/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ config.py           # ConfiguraciÃ³n centralizada
â”‚   â”œâ”€â”€ download_data.py    # Descarga del dataset
â”‚   â”œâ”€â”€ preprocessing.py    # Pipeline de preprocesamiento
â”‚   â”œâ”€â”€ train.py           # Pipeline de entrenamiento
â”‚   â”œâ”€â”€ main.py            # API FastAPI
â”‚   â””â”€â”€ monitoring.py      # Sistema de monitoreo
â”œâ”€â”€ tests/
â”‚   â””â”€â”€ test_system.py     # Tests unitarios
â”œâ”€â”€ data/                  # Datasets (gitignored)
â”œâ”€â”€ models/                # Modelos entrenados (gitignored)
â”œâ”€â”€ logs/                  # Logs de predicciones
â”œâ”€â”€ mlruns/               # MLflow tracking
â”œâ”€â”€ requirements.txt      # Dependencias Python
â”œâ”€â”€ setup.py             # InstalaciÃ³n del paquete
â”œâ”€â”€ Dockerfile           # Imagen Docker
â”œâ”€â”€ docker-compose.yml   # OrquestaciÃ³n de servicios
â”œâ”€â”€ setup.sh            # Script de setup
â”œâ”€â”€ train.sh            # Script de entrenamiento
â””â”€â”€ run_api.sh          # Script para iniciar API
```

## ðŸ”¬ Pipeline de Entrenamiento

### Componentes

1. **Data Download** (`download_data.py`)
   - Descarga automÃ¡tica desde Kaggle usando `kagglehub`
   - ValidaciÃ³n de datos (missing values, tipos, estadÃ­sticas)
   - Guardado en formato CSV

2. **Preprocessing** (`preprocessing.py`)
   - Limpieza de datos (missing values, duplicados)
   - IdentificaciÃ³n automÃ¡tica de features y target
   - Split train/test (80/20)
   - StandardizaciÃ³n con `StandardScaler`
   - Persistencia del preprocessor para inferencia

3. **Training** (`train.py`)
   - Entrenamiento de mÃºltiples modelos:
     - Linear Regression (baseline)
     - Ridge Regression
     - Random Forest Regressor
     - Gradient Boosting Regressor
   - Tracking automÃ¡tico con MLflow:
     - ParÃ¡metros
     - MÃ©tricas (RMSE, MAE, RÂ²)
     - Artefactos (modelo, preprocessor)
   - SelecciÃ³n del mejor modelo
   - Guardado en `/models/production/`

### MÃ©tricas Evaluadas

- **RMSE**: Error cuadrÃ¡tico medio (penaliza outliers)
- **MAE**: Error absoluto medio (interpretable)
- **RÂ²**: Varianza explicada (0-1, mayor es mejor)

### Reproducibilidad

- Seeds fijos (`random_state=42`)
- Versionado de cÃ³digo con Git
- Tracking completo con MLflow
- ConfiguraciÃ³n centralizada (`.env` y `params.yaml`)

### ðŸ“‹ ConfiguraciÃ³n con params.yaml

**NUEVO:** El proyecto ahora incluye `params.yaml` para centralizar hiperparÃ¡metros y configuraciones, inspirado en [mejores prÃ¡cticas de MLOps](https://github.com/entbappy/End-to-end-Youtube-Sentiment).

#### Beneficios

- âœ… **ExperimentaciÃ³n sin modificar cÃ³digo**: Cambia hiperparÃ¡metros editando YAML
- âœ… **Reproducibilidad**: Versionado de configuraciones con Git
- âœ… **Tracking automÃ¡tico**: MLflow registra todos los parÃ¡metros
- âœ… **ColaboraciÃ³n**: Equipo puede compartir configuraciones fÃ¡cilmente

#### Ejemplo de Uso

```yaml
# params.yaml
model_building:
  random_forest:
    n_estimators: 200     # Cambiar de 100 a 200
    max_depth: 15         # Aumentar profundidad
    min_samples_split: 5  # Reducir overfitting
```

```bash
# Reentrenar con nuevos parÃ¡metros

python src/train.py
```

MLflow automÃ¡ticamente registra todos los cambios y permite comparar experimentos.

#### Artefactos Visuales Mejorados

El pipeline ahora genera automÃ¡ticamente plots de evaluaciÃ³n en cada entrenamiento:

- **Predictions vs Actual**: Visualiza precisiÃ³n del modelo
- **Residuals Plot**: Detecta patrones en errores
- **Residuals Distribution**: Valida normalidad de residuos
- **Feature Importance**: Top 15 features mÃ¡s importantes (RF/GB)

Todos los plots se guardan automÃ¡ticamente en MLflow como artefactos.

#### GuÃ­a Completa

Ver [PARAMS_GUIDE.md](PARAMS_GUIDE.md) para:
- ExplicaciÃ³n detallada de cada parÃ¡metro
- Ejemplos de tuning
- Best practices
- Troubleshooting

## ðŸŒ API REST

### Endpoints Principales

#### `POST /predict`
PredicciÃ³n individual de precio de vivienda.

**Request:**
```json
{
  "CRIM": 0.00632,
  "ZN": 18.0,
  "INDUS": 2.31,
  "CHAS": 0.0,
  "NOX": 0.538,
  "RM": 6.575,
  "AGE": 65.2,
  "DIS": 4.0900,
  "RAD": 1.0,
  "TAX": 296.0,
  "PTRATIO": 15.3,
  "B": 396.90,
  "LSTAT": 4.98
}
```

**Response:**
```json
{
  "prediction": 30.12,
  "model_version": "1.0.0",
  "inference_time": 0.0023
}
```

#### `POST /predict/batch`
Predicciones en batch para mÃºltiples entradas.

#### `GET /health`
Health check del servicio.

**Response:**
```json
{
  "status": "healthy",
  "model_loaded": true,
  "uptime_hours": 2.5,
  "total_predictions": 157,
  "warnings": []
}
```

#### `GET /metrics`
MÃ©tricas de monitoreo.

**Response:**
```json
{
  "total_predictions": 157,
  "avg_inference_time": 0.0024,
  "p95_inference_time": 0.0035,
  "avg_prediction": 22.5,
  "std_prediction": 9.2,
  "uptime_hours": 2.5
}
```

#### `GET /model/info`
InformaciÃ³n del modelo en producciÃ³n.

#### `POST /admin/reload`
Recargar modelo sin reiniciar el servicio.

### DocumentaciÃ³n Interactiva

- **Swagger UI**: http://localhost:8000/docs
- **ReDoc**: http://localhost:8000/redoc

## ðŸ“Š Monitoreo

### Sistema de Monitoreo (`monitoring.py`)

El sistema incluye monitoreo comprehensivo en producciÃ³n:

#### 1. **MÃ©tricas de Performance**
- Latencia de inferencia (avg, p50, p95, p99)
- Throughput (predicciones/hora)
- Uptime del servicio

#### 2. **Logging de Predicciones**
- Todas las predicciones se registran con:
  - Timestamp
  - Features de entrada
  - PredicciÃ³n
  - Tiempo de inferencia
- Guardado periÃ³dico en `/logs/`

#### 3. **Data Drift Detection**
- ComparaciÃ³n de estadÃ­sticas de features vs baseline
- Alerta si mean se desvÃ­a > 2 std
- Ãštil para detectar cambios en distribuciÃ³n de datos

#### 4. **Health Checks**
- VerificaciÃ³n de estado del modelo
- DetecciÃ³n de anomalÃ­as (ej. alta latencia)
- Status: `healthy`, `degraded`, `warning`

### Ejemplo de Uso

```python
from monitoring import monitor

# El monitor se actualiza automÃ¡ticamente con cada predicciÃ³n
metrics = monitor.get_metrics()
health = monitor.get_health_status()
drift = monitor.detect_drift(baseline_stats)
```

## ðŸ³ Despliegue

### Docker Compose

El proyecto incluye `docker-compose.yml` con dos servicios:

1. **MLflow Server** (Puerto 5000)
   - Tracking server
   - Backend: file system
   - Artifacts: local storage

2. **API Service** (Puerto 8000)
   - FastAPI application
   - Auto-reload en desarrollo
   - Health checks configurados

```bash
# Desarrollo
docker-compose up

# ProducciÃ³n (detached)
docker-compose up -d

# Ver logs
docker-compose logs -f api

# Escalar API
docker-compose up --scale api=3
```

### Kubernetes (Ejemplo)

```yaml
# deployment.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: housing-api
spec:
  replicas: 3
  selector:
    matchLabels:
      app: housing-api
  template:
    metadata:
      labels:
        app: housing-api
    spec:
      containers:
      - name: api
        image: housing-price-api:latest
        ports:
        - containerPort: 8000
        env:
        - name: MLFLOW_TRACKING_URI
          value: "http://mlflow-service:5000"
        livenessProbe:
          httpGet:
            path: /health
            port: 8000
          initialDelaySeconds: 30
          periodSeconds: 10
        resources:
          requests:
            memory: "512Mi"
            cpu: "500m"
          limits:
            memory: "1Gi"
            cpu: "1000m"
```

## ðŸ’¡ Decisiones TÃ©cnicas

### 1. **Stack AgnÃ³stico Cloud**
**DecisiÃ³n**: Usar solo herramientas open-source (MLflow, FastAPI, Docker)

**JustificaciÃ³n**:
- âœ… Portabilidad total entre proveedores
- âœ… Sin vendor lock-in
- âœ… Control completo del stack
- âœ… Costos predecibles
- âŒ Menos features managed (auto-scaling, managed infra)

**Alternativas consideradas**: AWS SageMaker, Google AI Platform, Azure ML

### 2. **MLflow para Experiment Tracking**
**DecisiÃ³n**: MLflow open-source con backend de archivos

**JustificaciÃ³n**:
- âœ… Industry standard
- âœ… UI integrada para visualizaciÃ³n
- âœ… Versionado de modelos
- âœ… FÃ¡cil migraciÃ³n a backends robustos (PostgreSQL, S3)
- âœ… API Python simple

**Alternativas consideradas**: Weights & Biases, Neptune.ai, DVC

### 3. **FastAPI como Framework Web**
**DecisiÃ³n**: FastAPI sobre Flask/Django

**JustificaciÃ³n**:
- âœ… Performance superior (async/await)
- âœ… ValidaciÃ³n automÃ¡tica con Pydantic
- âœ… DocumentaciÃ³n auto-generada (OpenAPI/Swagger)
- âœ… Type hints nativos
- âœ… DiseÃ±ado para APIs modernas

**Benchmarks**: ~3x mÃ¡s rÃ¡pido que Flask en I/O bound tasks

### 4. **MÃºltiples Modelos con SelecciÃ³n AutomÃ¡tica**
**DecisiÃ³n**: Entrenar 4 modelos y seleccionar el mejor por RMSE

**JustificaciÃ³n**:
- âœ… ValidaciÃ³n de que modelo simple no es suficiente
- âœ… ComparaciÃ³n justa con mismos datos
- âœ… Random Forest ganÃ³ consistentemente (mejor bias-variance tradeoff)
- âœ… Tracking de todos los experimentos

**Modelos probados**:
1. Linear Regression (baseline)
2. Ridge (regularizaciÃ³n L2)
3. Random Forest (ensemble, no lineal)
4. Gradient Boosting (ensemble secuencial)

### 5. **Monitoreo In-Process**
**DecisiÃ³n**: Monitoreo dentro del proceso de la API

**JustificaciÃ³n**:
- âœ… Simplicidad (no requiere infra adicional)
- âœ… Suficiente para MVP
- âœ… FÃ¡cil evoluciÃ³n a Prometheus/Grafana
- âŒ No persistente entre reinicios

**Mejora futura**: Exportar a Prometheus + Grafana

### 6. **StandardScaler vs Min-Max**
**DecisiÃ³n**: StandardScaler para normalizaciÃ³n

**JustificaciÃ³n**:
- âœ… No asume rango fijo [0,1]
- âœ… Robusto a outliers
- âœ… Funciona bien con modelos lineales y tree-based
- âœ… Preserva estructura de outliers

### 7. **Estructura Modular**
**DecisiÃ³n**: SeparaciÃ³n clara de concerns

**JustificaciÃ³n**:
- âœ… Testeable independientemente
- âœ… Reutilizable (preprocessing en train e inference)
- âœ… Extensible (fÃ¡cil agregar nuevos modelos)
- âœ… Mantenible

```
config.py          â†’ ConfiguraciÃ³n centralizada
preprocessing.py   â†’ LÃ³gica de datos
train.py          â†’ Pipeline de entrenamiento
main.py           â†’ API
monitoring.py     â†’ Observabilidad
```

## ðŸš€ Mejoras Futuras

### Corto Plazo (1-2 sprints)

1. **Feature Engineering**
   - Interacciones entre features (RM * DIS)
   - Transformaciones no lineales (log, sqrt)
   - Binning de variables continuas

2. **Hyperparameter Tuning**
   - Grid Search o Random Search
   - Optuna para optimizaciÃ³n bayesiana
   - ValidaciÃ³n cruzada k-fold

3. **Model Validation**
   - Cross-validation en entrenamiento
   - AnÃ¡lisis de residuos
   - Feature importance

4. **Testing Mejorado**
   - Tests de integraciÃ³n end-to-end
   - Tests de carga (locust)
   - Contract testing para API

### Medio Plazo (3-6 meses)

5. **Monitoreo Avanzado**
   - IntegraciÃ³n con Prometheus + Grafana
   - Alertas automÃ¡ticas (PagerDuty, Slack)
   - Dashboards de mÃ©tricas de negocio

6. **Data Drift Detection Robusto**
   - Kolmogorov-Smirnov test
   - Population Stability Index (PSI)
   - Reentrenamiento automÃ¡tico si drift > threshold

7. **A/B Testing**
   - Framework para probar modelos nuevos
   - Traffic splitting
   - MÃ©tricas de negocio

8. **Model Registry**
   - Versionado de modelos con MLflow Registry
   - Staging â†’ Production promotion
   - Rollback automÃ¡tico

### Largo Plazo (6-12 meses)

9. **Feature Store**
   - Feast o Tecton
   - Features compartidas entre modelos
   - Consistencia train/serve

10. **Advanced Deployment**
    - Blue-green deployment
    - Canary releases
    - Shadow mode

11. **AutoML**
    - Auto-sklearn o H2O AutoML
    - ExploraciÃ³n automÃ¡tica de modelos
    - Feature engineering automÃ¡tico

12. **Seguridad**
    - AutenticaciÃ³n API (OAuth2, API keys)
    - Rate limiting
    - Input validation mÃ¡s estricta
    - EncriptaciÃ³n de datos sensibles

13. **Escalabilidad**
    - Kubernetes con HPA
    - Cache de predicciones (Redis)
    - Batch inference optimizado
    - GPU para modelos complejos

14. **Compliance & Governance**
    - Lineage de datos
    - Explicabilidad (SHAP, LIME)
    - Audit logs
    - GDPR compliance

## ðŸ¤– Uso de Herramientas AI

Este proyecto fue desarrollado con asistencia de **GitHub Copilot** y **GPT-4** en las siguientes Ã¡reas:

### Copilot (Inline suggestions)
- âœ… Autocompletado de funciones repetitivas
- âœ… GeneraciÃ³n de docstrings
- âœ… Sugerencias de tipo hints
- âœ… Patrones de cÃ³digo comunes

### GPT-4 (Chat-based)
- âœ… DiseÃ±o de arquitectura MLOps
- âœ… RevisiÃ³n de decisiones tÃ©cnicas
- âœ… GeneraciÃ³n de tests unitarios
- âœ… Escritura de documentaciÃ³n
- âœ… Troubleshooting de errores

### CÃ³digo Escrito Manualmente
- âœ… LÃ³gica de negocio core (preprocessing, training)
- âœ… ConfiguraciÃ³n de MLflow
- âœ… DiseÃ±o de API endpoints
- âœ… IntegraciÃ³n de componentes

### ValidaciÃ³n
- âœ… Todo el cÃ³digo fue revisado manualmente
- âœ… Tests ejecutados y pasando
- âœ… Best practices validadas
- âœ… Security considerations aplicadas

**Nota**: Las herramientas AI aceleraron el desarrollo ~30-40%, especialmente en tareas repetitivas y documentaciÃ³n.

## ðŸ“š Referencias

- [MLflow Documentation](https://mlflow.org/docs/latest/index.html)
- [FastAPI Documentation](https://fastapi.tiangolo.com/)
- [scikit-learn Documentation](https://scikit-learn.org/)
- [Boston Housing Dataset](https://www.kaggle.com/datasets/altavish/boston-housing-dataset)
- [MLOps Best Practices](https://ml-ops.org/)
- [Google MLOps Principles](https://cloud.google.com/architecture/mlops-continuous-delivery-and-automation-pipelines-in-machine-learning)

## ðŸ‘¤ Autor

**Mateo Restrepo**
- GitHub: [@marestrepohi](https://github.com/marestrepohi)
- Proyecto: Prueba TÃ©cnica MLOps - MercadoLibre

## ðŸ“„ Licencia

Este proyecto es para fines educativos y de evaluaciÃ³n tÃ©cnica.

---

**Â¿Preguntas?** Abre un issue o contacta al autor.

**Para la presentaciÃ³n**: Revisar secciones de Arquitectura, Decisiones TÃ©cnicas y Mejoras Futuras. ðŸš€
