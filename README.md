# üè† Predicci√≥n de Precios de Viviendas - Sistema MLOps Completo

[![Pipeline CI/CD](https://img.shields.io/badge/CI%2FCD-GitHub%20Actions-blue)](https://github.com/marestrepohi/meli-mlops-mateo-restrepo/actions)
[![Python 3.11+](https://img.shields.io/badge/python-3.11+-blue.svg)](https://www.python.org/downloads/)
[![FastAPI](https://img.shields.io/badge/FastAPI-0.104+-green.svg)](https://fastapi.tiangolo.com/)
[![MLflow](https://img.shields.io/badge/MLflow-2.8+-orange.svg)](https://mlflow.org/)
[![Docker](https://img.shields.io/badge/Docker-Compose-blue.svg)](https://docs.docker.com/compose/)
[![Colaboraci√≥n](https://img.shields.io/badge/Creado%20con-GitHub%20Copilot-ffd700.svg)](https://github.com/features/copilot)
[![Licencia](https://img.shields.io/badge/licencia-MIT-blue.svg)](LICENSE)

---
## üë§ Autor

**Mateo Restrepo**
- GitHub: [@marestrepohi](https://github.com/marestrepohi)
- LinkedIn: [mateo-restrepo](https://www.linkedin.com/in/mateorestrepohiguita-datascientist/)
---



<div align="center">

## üé• Video Demo del Proyecto

[![Ver Video Demo](https://img.shields.io/badge/‚ñ∂Ô∏è-Ver_Video_Completo-red?style=for-the-badge&logo=youtube)](https://drive.google.com/file/d/1MZXWTC2SF8O0-vJjvufFEhiZZ7-SA7KM/view?usp=sharing)

### üéØ Dashboard MLOps Completo
<img src="meli_mlops.png" alt="Dashboard MLOps" width="800"/>

### üîµ API REST con FastAPI
<img src="meli_api.png" alt="API FastAPI" width="800"/>

### üìä MLflow Tracking UI
<img src="meli_mlflow.png" alt="MLflow UI" width="800"/>

</div>

---

> ü§ñ **Sistema completo y producci√≥n-ready de MLOps** para predicci√≥n de precios de viviendas. 
> Soluci√≥n agn√≥stica a la nube con tecnolog√≠as open-source, pipeline reproducible, API REST, monitoreo continuo y CI/CD automatizado. 
> **Este proyecto fue co-creado con GitHub Copilot** integrando t√©cnicas modernas de IA en todo el ciclo de desarrollo.

---

## üìã Objetivo del Proyecto

Este proyecto implementa una **soluci√≥n end-to-end de Machine Learning Operations (MLOps)** para predecir precios de viviendas utilizando el dataset Boston Housing. 

### üéØ Objetivos Clave

1. ‚úÖ **Reproducibilidad Total**: Pipeline versionado con DVC y Git
2. ‚úÖ **Agn√≥stico a Cloud**: Solo herramientas open-source y self-hosted
3. ‚úÖ **Monitoreo en Tiempo Real**: Tracking de performance, latencia y data drift
4. ‚úÖ **Escalabilidad**: Arquitectura containerizada lista para Kubernetes
5. ‚úÖ **Mantenibilidad**: C√≥digo modular, documentado y testeado
6. ‚úÖ **Automatizaci√≥n**: CI/CD completo con GitHub Actions
7. ‚úÖ **Interferencia √ìptima**: API REST con validaci√≥n y seguridad


## ÔøΩüöÄ Inicio R√°pido - 2 Opciones

### Opci√≥n 1Ô∏è‚É£: Con Docker - Makefile (RECOMENDADO - M√°s F√°cil)

**Requisitos:**
- ‚úÖ Docker y linux instalado (descargar desde https://www.docker.com/products/docker-desktop)
- ‚úÖ Git

**Pasos:**

```bash
# 1. Clonar el repositorio
git clone https://github.com/marestrepohi/meli-mlops-mateo-restrepo.git
cd meli-mlops-mateo-restrepo


# 1. Iniciar todos los servicios (DVC Pipeline + API + MLflow + Frontend)

make start          -  Construir + Iniciar todos los servicios (RECOMENDADO)

## Otros comandos
make build          - Construir todas las im√°genes Docker
make up             - Iniciar todos los servicios (API, MLflow, Frontend)
make down           - Detener y remover todos los contenedores
make restart        - Reiniciar todos los servicios


```

**¬øQu√© sucede autom√°ticamente?**
```
‚îú‚îÄ 1. Pipeline DVC se ejecuta (descarga datos, prepara, entrena modelo)
‚îú‚îÄ 2. Mejor modelo se exporta a models/production/latest/
‚îú‚îÄ 3. MLflow UI se inicia en puerto 5000
‚îú‚îÄ 4. FastAPI inicia en puerto 8000
‚îî‚îÄ 5. Frontend Vite inicia en puerto 8080
```

---

### Opci√≥n 2Ô∏è‚É£: Pasos Manuales (Setup Local)

**Requisitos:**
- ‚úÖ Python 3.11+ instalado
- ‚úÖ Git

**Pasos:**

```bash
# 1. Clonar repositorio
git clone https://github.com/marestrepohi/meli-mlops-mateo-restrepo.git
cd meli-mlops-mateo-restrepo
cp .env.example .env

# 2. Crear entorno virtual
python3 -m venv venv
source venv/bin/activate           # En Mac/Linux


# 3. Instalar dependencias Python
pip install -r requirements.txt

# 4. Ejecutar pipeline DVC (data + training)
dvc init               # Solo la primera vez
dvc repro

# 5. En terminal 1: Iniciar API
uvicorn api.main:app --reload --port 8000

# 6. En terminal 2: Iniciar MLflow UI
mlflow ui --port 5000

# 8. En terminal 3: Iniciar Frontend
cd front && npm install && npm run dev
```

---

## üìä Servicios Disponibles

| Servicio | Puerto | URL | Descripci√≥n |
|----------|--------|-----|-------------|
| **API (FastAPI)** | 8000 | http://localhost:8000 | REST API con predicciones en tiempo real |
| **Swagger Docs** | 8000 | http://localhost:8000/docs | Documentaci√≥n interactiva |
| **MLflow UI** | 5000 | http://localhost:5000 | Tracking de experimentos y modelos |
| **Frontend** | 8080 | http://localhost:8080 o http://localhost:8082 | Dashboard web interactivo |

---
## üß™ Testear la API

### Test 1: Health Check (Verificar que API est√° activa)

```bash
curl http://localhost:8000/health
```

**Respuesta esperada:**
```json
{
  "status": "healthy",
  "model_loaded": true,
  "scaler_loaded": true,
  "model_name": "boston_housing_xgboost",
  "model_version": "1.0",
  "total_predictions": 0
}
```

---

### Test 2: Predicci√≥n Individual (Puerto 8000)

**Ejemplo: Predecir precio de una vivienda en Boston**

```bash
curl -X POST http://localhost:8000/predict \
  -H "Content-Type: application/json" \
  -d '{
    "CRIM": 0.00632,
    "ZN": 18.0,
    "INDUS": 2.31,
    "CHAS": 0.0,
    "NOX": 0.538,
    "RM": 6.575,
    "AGE": 65.2,
    "DIS": 4.09,
    "RAD": 1.0,
    "TAX": 296.0,
    "PTRATIO": 15.3,
    "B": 396.90,
    "LSTAT": 4.98
  }'
```

**Respuesta esperada:**
```json
{
  "prediction": 24.5,
  "model_name": "boston_housing_xgboost",
  "model_version": "v1.0",
  "model_stage": "Production",
  "inference_time": 12.34,
  "features_used": ["CRIM", "NOX", "RM", "AGE", "DIS", "RAD", "TAX", "PTRATIO", "B", "LSTAT"]
}
```

---

### Test 3: Predicciones en Batch

```bash
curl -X POST http://localhost:8000/predict/batch \
  -H "Content-Type: application/json" \
  -d '{
    "data": [
      {"CRIM": 0.00632, "NOX": 0.538, "RM": 6.575, "AGE": 65.2, "DIS": 4.09, "RAD": 1, "TAX": 296, "PTRATIO": 15.3, "B": 396.9, "LSTAT": 4.98},
      {"CRIM": 0.02731, "NOX": 0.469, "RM": 6.421, "AGE": 78.9, "DIS": 4.9671, "RAD": 2, "TAX": 242, "PTRATIO": 17.8, "B": 396.9, "LSTAT": 9.14}
    ]
  }'
```

**Respuesta esperada:**
```json
{
  "predictions": [
    {
      "index": 0,
      "prediction": 24.5,
      "inference_time_ms": 8.23
    },
    {
      "index": 1,
      "prediction": 21.8,
      "inference_time_ms": 7.45
    }
  ],
  "count": 2,
  "model_version": "v1.0",
  "total_inference_time": 15.68,
  "avg_inference_time": 7.84
}
```


## üîÑ Flujo del Proyecto 

### Fase 1Ô∏è‚É£: Experimentaci√≥n y Exploraci√≥n (Notebooks)

**Archivos:** 
- `notebooks/data_extract_eda.ipynb` - An√°lisis Exploratorio de Datos
- `notebooks/model_train.ipynb` - Experimentaci√≥n con modelos

En esta fase inicial, se realiza:

```
1. Descargar datos de Kaggle (Boston Housing)
2. An√°lisis Exploratorio de Datos (EDA):
   - Distribuciones de variables
   - Correlaci√≥n de features
   - Detecci√≥n de outliers
3. Generaci√≥n de reportes automatizados con ydata-profiling
4. Experimentaci√≥n con diferentes modelos y hiperpar√°metros
5. Validaci√≥n de resultados
```

**Salida:** 
- Reportes en `data/reports/eda_data.json`
- Insights sobre variables m√°s importantes
- Decisiones de modelo para pipeline

---

### Fase 2Ô∏è‚É£: Pipeline DVC (Reproducibilidad)

**Archivos:** `dvc.yaml`, `params.yaml`, `src/*.py`

Basado en los aprendizajes de la experimentaci√≥n, se cre√≥ un **pipeline automatizado** con 4 etapas:

#### üì• Etapa 1: Data Ingestion (`src/data_ingestion.py`)
```bash
- Descarga datos de Kaggle API
- Genera reporte EDA autom√°tico
- Output: data/raw/HousingData.csv
```

#### üßπ Etapa 2: Data Preparation (`src/data_preparation.py`)
```bash
- Limpieza de valores nulos (mediana/moda)
- Split train/test (80/20 con seed=42)
- StandardScaler para normalizaci√≥n
- Output: data/processed/*.csv + models/production/latest/scaler.pkl
```

#### ü§ñ Etapa 3: Model Training (`src/model_train.py`)
```bash
Ejecuta 3 EXPERIMENTOS XGBoost con MLflow:

‚úÖ Experimento 1 - Hyperparameter Tuning (Todas las 13 features)
   ‚îú‚îÄ RandomizedSearchCV con 50 iteraciones
   ‚îú‚îÄ 5-fold cross-validation

‚úÖ Experimento 2 - Feature Importance con SHAP
   ‚îú‚îÄ Selecciona top features (percentil 20)
   ‚îú‚îÄ ~10 features m√°s importantes

‚úÖ Experimento 3 - Tuning en Features Seleccionadas ‚≠ê GANADOR
   ‚îú‚îÄ Hiperpar√°metros optimizados para features seleccionadas
   ‚îú‚îÄ Balance entre performance y complejidad


üèÜ El MEJOR modelo (Experimento 3) se exporta AUTOM√ÅTICAMENTE a:
   - models/production/latest/model.pkl
   - models/production/latest/scaler.pkl
   - models/production/latest/metadata.json
```

#### üì¶ Etapa 4: Model Registration (`src/model_register.py`)
```bash
- Lee metadata del mejor modelo (generada por model_train.py)
- Registra autom√°ticamente en MLflow Model Registry
- Transiciona a stage "Production"
- Agrega tags y documentaci√≥n
- Archiva versiones antiguas
```

**Ejecuci√≥n del pipeline:**

El pipeline est√° implementado con **DVC** para reproducibilidad completa:

```bash
dvc repro                    # Ejecuta TODO el pipeline
dvc dag                      # Visualiza DAG del pipeline
make dvc-repro              # Ejecuta desde Make
```

---

### Fase 3Ô∏è‚É£: API REST para Producci√≥n (FastAPI)

**Archivo:** `api/main.py`

Una vez el modelo est√° entrenado y registrado, se **consume autom√°ticamente** en la API:

#### üîµ Endpoints Principales:

```bash
‚úÖ Health Check
GET /health
‚Üí Verifica que el modelo est√° cargado

‚úÖ Predicci√≥n Individual  
POST /predict
{
  "CRIM": 0.00632,
  "NOX": 0.538,
  "RM": 6.575,
  "AGE": 65.2,
  "DIS": 4.09,
  "RAD": 1.0,
  "TAX": 296.0,
  "PTRATIO": 15.3,
  "B": 396.90,
  "LSTAT": 4.98
}
‚Üí Retorna predicci√≥n + metadata

‚úÖ Predicciones en Batch
POST /predict/batch
{"data": [... m√∫ltiples registros ...]}
‚Üí Procesa varios registros eficientemente

‚úÖ M√©tricas de Monitoreo
GET /metrics
‚Üí Total predicciones, latencia, uptime

‚úÖ Detecci√≥n de Drift
GET /monitoring/drift
‚Üí Compara con baseline para detectar cambios

‚úÖ Dashboard de Monitoreo
GET /monitoring/dashboard
‚Üí HTML interactivo con m√©tricas en tiempo real
```


### Fase 4Ô∏è‚É£: Monitoreo Continuo

**Archivo:** `api/monitoring.py`

Tracking autom√°tico de predicciones en producci√≥n:

```bash
‚úÖ M√©tricas capturadas:
   - Total de predicciones
   - Tiempo de inferencia (p50, p95, p99)
   - Distribuci√≥n de predicciones
   - Detecci√≥n de data drift

‚úÖ Baselines:
   - Se pueden configurar manualmente
   - Detecta cambios en distribuci√≥n
   - Alerta si hay drift significativo
```

---

## üìä Monitoreo

Sistema de monitoreo completo implementado en `api/monitoring.py`:

### M√©tricas Rastreadas

1. **Performance Metrics**
   - Total de predicciones
   - Uptime del servicio
   - Predicciones por hora

2. **Latency Metrics**
   - Tiempo promedio de inferencia
   - Percentiles: p50, p95, p99
   - Tiempo m√°ximo de inferencia

3. **Prediction Statistics**
   - Media, mediana, std de predicciones
   - Min/max values
   - Distribuci√≥n de predicciones

4. **Data Drift Detection**
   - Comparaci√≥n vs baseline (mean ¬± 2œÉ)
   - Drift score por feature
   - Alertas autom√°ticas

### Configurar Baseline para Drift Detection

```python
from api.monitoring import monitor

# Configurar baseline con datos hist√≥ricos
historical_predictions = [20.5, 22.3, 19.8, ...]
historical_features = {
    'CRIM': [0.1, 0.2, ...],
    'RM': [6.0, 6.5, ...]
}

monitor.set_baseline(historical_predictions, historical_features)
```

---

### Fase 5Ô∏è‚É£: Frontend Interactivo

**Carpeta:** `front/`

Interfaz web moderna con React + Vite:

```bash
‚úÖ Formulario para hacer predicciones
‚úÖ Visualizaci√≥n de resultados en tiempo real
‚úÖ Dashboard de monitoreo con gr√°ficos
‚úÖ Hist√≥rico de predicciones
‚úÖ Estad√≠sticas de performance
```

**Acceso:** http://localhost:8080

---

### Fase 6Ô∏è‚É£: CI/CD Automatizado (GitHub Actions)

**Carpeta:** `.github/workflows/`

Automatizaci√≥n completa en cada push:

```bash
‚úÖ mlops-ci-cd.yml (Pipeline Principal)
   1. Code Quality: flake8 + pytest
   2. Train Model: Ejecuta DVC pipeline
   3. Build Docker: Construye im√°genes
   4. Test API: Verifica todos los endpoints
   5. Deploy: Prepara para producci√≥n

‚úÖ Ejecuci√≥n autom√°tica en:
   - Push a main/develop
   - Pull requests
   - Manual workflow_dispatch
```

---

## üìÇ Estructura Completa del Proyecto

```
meli-mlops-mateo-restrepo/
‚îÇ
‚îú‚îÄ‚îÄ üìì NOTEBOOKS (Experimentaci√≥n y EDA)
‚îÇ   ‚îú‚îÄ‚îÄ notebooks/data_extract_eda.ipynb        # EDA interactivo del dataset
‚îÇ   ‚îî‚îÄ‚îÄ notebooks/model_train.ipynb             # Experimentaci√≥n con modelos
‚îÇ
‚îú‚îÄ‚îÄ üîÑ PIPELINE DVC (Reproducibilidad Total)
‚îÇ   ‚îú‚îÄ‚îÄ dvc.yaml                                # Definici√≥n DAG del pipeline
‚îÇ   ‚îú‚îÄ‚îÄ params.yaml                             # Hiperpar√°metros centralizados
‚îÇ   ‚îî‚îÄ‚îÄ src/
‚îÇ       ‚îú‚îÄ‚îÄ config.py                           # Configuraci√≥n global
‚îÇ       ‚îú‚îÄ‚îÄ data_ingestion.py                   # Etapa 1: Descargar datos
‚îÇ       ‚îú‚îÄ‚îÄ data_preparation.py                 # Etapa 2: Limpieza + split + scale
‚îÇ       ‚îú‚îÄ‚îÄ model_train.py                      # Etapa 3: 3 experimentos XGBoost
‚îÇ       ‚îî‚îÄ‚îÄ model_register.py                   # Etapa 4: Registrar en MLflow
‚îÇ
‚îú‚îÄ‚îÄ üîµ API REST (FastAPI con Monitoreo)
‚îÇ   ‚îú‚îÄ‚îÄ api/main.py                             # API principal + endpoints
‚îÇ   ‚îú‚îÄ‚îÄ api/monitoring.py                       # Monitoreo + drift detection
‚îÇ   ‚îî‚îÄ‚îÄ api/__init__.py
‚îÇ
‚îú‚îÄ‚îÄ üåê FRONTEND (React + Vite + Tailwind)
‚îÇ   ‚îú‚îÄ‚îÄ front/src/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ components/                         # Componentes React
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ pages/                              # P√°ginas
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ services/                           # Llamadas a API
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ main.tsx
‚îÇ   ‚îú‚îÄ‚îÄ front/package.json
‚îÇ   ‚îú‚îÄ‚îÄ front/vite.config.ts
‚îÇ   ‚îî‚îÄ‚îÄ front/tailwind.config.ts
‚îÇ
‚îú‚îÄ‚îÄ üê≥ DOCKER (Contenedorizaci√≥n)
‚îÇ   ‚îú‚îÄ‚îÄ Dockerfile                              # Imagen Python backend
‚îÇ   ‚îú‚îÄ‚îÄ docker-compose.yml                      # Orquestaci√≥n servicios
‚îÇ   ‚îî‚îÄ‚îÄ .dockerignore
‚îÇ
‚îú‚îÄ‚îÄ ü§ñ CI/CD (GitHub Actions)
‚îÇ   ‚îî‚îÄ‚îÄ .github/workflows/
‚îÇ       ‚îú‚îÄ‚îÄ mlops-ci-cd.yml                     # Pipeline principal
‚îÇ       ‚îî‚îÄ‚îÄ mlops-pipeline-ultra-simple.yml.old # Versi√≥n simplificada
‚îÇ
‚îú‚îÄ‚îÄ üìä DATOS (Versionados con DVC)
‚îÇ   ‚îú‚îÄ‚îÄ data/raw/                               # Datos originales de Kaggle
‚îÇ   ‚îú‚îÄ‚îÄ data/processed/                         # Datos preprocesados (train/test)
‚îÇ   ‚îú‚îÄ‚îÄ data/predictions/                       # Hist√≥rico de predicciones
‚îÇ   ‚îî‚îÄ‚îÄ data/reports/                           # Reportes EDA JSON/HTML
‚îÇ
‚îú‚îÄ‚îÄ üéØ MODELOS (Producci√≥n Ready)
‚îÇ   ‚îú‚îÄ‚îÄ models/production/latest/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ model.pkl                           # Modelo XGBoost entrenado
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ scaler.pkl                          # StandardScaler serializado
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ metadata.json                       # Features, m√©tricas, timestamps
‚îÇ   ‚îî‚îÄ‚îÄ mlruns/                                 # MLflow experiment tracking
‚îÇ
‚îî‚îÄ‚îÄ üìã CONFIGURACI√ìN DEL PROYECTO
    ‚îú‚îÄ‚îÄ Makefile                                # Comandos Docker simplificados
    ‚îú‚îÄ‚îÄ requirements.txt                        # Dependencias Python
    ‚îú‚îÄ‚îÄ README.md                               
    ‚îú‚îÄ‚îÄ dvc.yaml
    ‚îú‚îÄ‚îÄ params.yaml
    ‚îî‚îÄ‚îÄ .env.example
 
---

## üèóÔ∏è Arquitectura Docker

### Docker Compose - Arquitectura Multi-Contenedor

El proyecto utiliza **Docker Compose** con una arquitectura de 3 servicios independientes:

```yaml
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                   Docker Compose Network                     ‚îÇ
‚îÇ                  (mlops-housing-network)                     ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ                                                              ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê     ‚îÇ
‚îÇ  ‚îÇ   Backend    ‚îÇ  ‚îÇ   MLflow     ‚îÇ  ‚îÇ   Frontend   ‚îÇ     ‚îÇ
‚îÇ  ‚îÇ   Container  ‚îÇ  ‚îÇ   Container  ‚îÇ  ‚îÇ   Container  ‚îÇ     ‚îÇ
‚îÇ  ‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§  ‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§  ‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§     ‚îÇ
‚îÇ  ‚îÇ Python 3.11  ‚îÇ  ‚îÇ Python 3.11  ‚îÇ  ‚îÇ Node 20      ‚îÇ     ‚îÇ
‚îÇ  ‚îÇ DVC + FastAPI‚îÇ  ‚îÇ MLflow UI    ‚îÇ  ‚îÇ Vite Dev     ‚îÇ     ‚îÇ
‚îÇ  ‚îÇ Port: 8000   ‚îÇ  ‚îÇ Port: 5000   ‚îÇ  ‚îÇ Port: 8080   ‚îÇ     ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò     ‚îÇ
‚îÇ         ‚îÇ                 ‚îÇ                  ‚îÇ              ‚îÇ
‚îÇ         ‚ñº                 ‚ñº                  ‚ñº              ‚îÇ
‚îÇ   ./data/           ./mlruns/          ./front/            ‚îÇ
‚îÇ   ./models/                                                 ‚îÇ
‚îÇ   ./mlruns/                                                 ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

### Servicios Docker

| Servicio | Imagen | Puerto | Funci√≥n | Comando Inicial |
|----------|--------|--------|---------|-----------------|
| **backend** | Python 3.11-slim | 8000 | DVC + FastAPI | `dvc repro ‚Üí uvicorn` |
| **mlflow** | Python 3.11-slim | 5000 | MLflow UI | `mlflow ui` |
| **frontend** | Node 20-alpine | 8080 | Vite Dev Server | `npm install ‚Üí npm run dev` |

### Archivos de Configuraci√≥n

```
docker-compose.yml       # Orquestaci√≥n de servicios
Dockerfile               # Imagen Python backend
.dockerignore           # Exclusiones de build
Makefile                # Comandos de gesti√≥n simplificados
```
---
## üéØ Conclusi√≥n: Pr√≥ximos Pasos - Integraci√≥n de Plataforma de Monitoreo

Este proyecto establece las bases de una **arquitectura MLOps moderna y escalable**. Sin embargo, para llevarla a **producci√≥n en empresas reales**, es fundamental integrar una **plataforma profesional de monitoreo y observabilidad**.

### üöÄ Roadmap de Integraci√≥n

#### **Actual (MVP - Fase Actual)**
```
‚úÖ Pipeline automatizado (DVC)
‚úÖ Model Registry (MLflow)
‚úÖ API REST (FastAPI)
‚úÖ Frontend b√°sico (React/Vite)
‚úÖ Monitoreo local en memoria
```

### üìù Frontend Interactivo como Base

**El dashboard del frontend ya implementado incluye:**

```
üé® Interfaz React moderna (puerto 8080)
‚îú‚îÄ üìä Panel de m√©tricas en tiempo real
‚îú‚îÄ üîç B√∫squeda de predicciones por fecha/rango
‚îú‚îÄ üìà Gr√°ficos de performance (RMSE, R¬≤, MAE)
‚îú‚îÄ üö® Alertas visuales de drift
‚îú‚îÄ üë• Historial de predicciones
‚îî‚îÄ ‚öôÔ∏è Configuraci√≥n de baselines

üîó Integraci√≥n pendiente:
   ‚Ä¢ Conectar a base de datos de producci√≥n
   ‚Ä¢ Mostrar m√©tricas reales desde plataforma de monitoreo
   ‚Ä¢ Alertas en UI basadas en thresholds configurables
   ‚Ä¢ Integrar herramientas de orquestaci√≥n como Airflow
```



**Este proyecto fue completamente co-creado con GitHub Copilot**, aprovechando potentes capacidades de IA para:

‚úÖ Generar c√≥digo de calidad producci√≥n desde el inicio  
‚úÖ Sugerir mejores pr√°cticas de MLOps  
‚úÖ Documentar autom√°ticamente cada componente  
‚úÖ Optimizar configuraciones de pipeline  
‚úÖ Acelerar el tiempo de desarrollo de semanas a d√≠as  
