# ğŸ  Housing Price Prediction - MLOps Production System

[![ML Pipeline CI/CD](https://github.com/marestrepohi/meli-mlops-mateo-restrepo/actions/workflows/ml-pipeline.yml/badge.svg)](https://github.com/marestrepohi/meli-mlops-mateo-restrepo/actions/workflows/ml-pipeline.yml)
[![Python 3.10+](https://img.shields.io/badge/python-3.10+-blue.svg)](https://www.python.org/downloads/)
[![FastAPI](https://img.shields.io/badge/FastAPI-0.104+-green.svg)](https://fastapi.tiangolo.com/)
[![MLflow](https://img.shields.io/badge/MLflow-2.8+-orange.svg)](https://mlflow.org/)
[![License](https://img.shields.io/badge/license-MIT-blue.svg)](LICENSE)

> Sistema completo y producciÃ³n-ready de MLOps para predicciÃ³n de precios de viviendas. ImplementaciÃ³n agnÃ³stica a la nube con tecnologÃ­as open-source, pipeline reproducible, API REST, monitoreo continuo y CI/CD automatizado.

---

## ğŸ“‹ DescripciÃ³n del Proyecto

Este proyecto implementa una soluciÃ³n end-to-end de Machine Learning Operations (MLOps) para **predecir precios de viviendas** utilizando el dataset Boston Housing. El sistema estÃ¡ diseÃ±ado siguiendo las mejores prÃ¡cticas de la industria y es completamente **agnÃ³stico a proveedores cloud**, utilizando Ãºnicamente herramientas open-source y self-hosted.

### ğŸ¯ Objetivos del Sistema

1. **Reproducibilidad**: Pipeline completamente versionado y automatizable
2. **Portabilidad**: TecnologÃ­as open-source, sin dependencias de servicios cloud gestionados
3. **Monitoreo**: Tracking de performance, latencia y data drift en tiempo real
4. **Escalabilidad**: Arquitectura containerizada lista para orquestadores (K8s, Docker Swarm)
5. **Mantenibilidad**: CÃ³digo modular, documentado y con tests comprehensivos

---

## ğŸ—ï¸ Arquitectura del Sistema

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                     PIPELINE DE ENTRENAMIENTO                    â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  1. Data Ingestion  â†’  2. Data Preparation  â†’  3. Model Train  â”‚
â”‚     (Kaggle API)        (Clean + Scale)         (XGBoost + MLflow)â”‚
â”‚         â†“                      â†“                        â†“         â”‚
â”‚   data/raw/           data/processed/          mlruns/ + models/  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                               â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    ARTEFACTOS DE PRODUCCIÃ“N                      â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  models/production/latest/                                       â”‚
â”‚    â”œâ”€â”€ model.pkl         (XGBoost model)                        â”‚
â”‚    â”œâ”€â”€ scaler.pkl        (StandardScaler)                       â”‚
â”‚    â””â”€â”€ metadata.json     (Features, metrics, run_id)            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                               â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                        API REST (FastAPI)                        â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  Endpoints:                                                      â”‚
â”‚    â€¢ POST /predict          (Individual prediction)             â”‚
â”‚    â€¢ POST /predict/batch    (Batch predictions)                 â”‚
â”‚    â€¢ GET  /health           (Health check)                      â”‚
â”‚    â€¢ GET  /metrics          (Performance metrics)               â”‚
â”‚    â€¢ GET  /drift            (Data drift detection)              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                               â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    MONITOREO Y OBSERVABILIDAD                    â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  â€¢ Prediction logging                                            â”‚
â”‚  â€¢ Latency tracking (p50, p95, p99)                             â”‚
â”‚  â€¢ Data drift detection (statistical tests)                     â”‚
â”‚  â€¢ Model performance monitoring                                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸš€ Inicio RÃ¡pido

### Prerequisitos

- **Docker** (recomendado para deployment completo)
- Python 3.10+ (para desarrollo local)
- Git
- Make (incluido en Linux/Mac, instalar en Windows con `choco install make`)

---

## ğŸ³ OpciÃ³n 1: Docker - Deployment Completo (RECOMENDADO)

### âš¡ Quick Start con Makefile

El proyecto incluye un **Makefile** completo para gestionar todo el ciclo de vida de Docker:

```bash
# 1. Clonar repositorio
git clone https://github.com/marestrepohi/meli-mlops-mateo-restrepo.git
cd meli-mlops-mateo-restrepo

# 2. Ver todos los comandos disponibles
make help

# 3. Construir imagen Docker (incluye Python env, DVC, API, MLflow, Frontend)
make build

# 4. Ejecutar todos los servicios
make run

# 5. Verificar que todo estÃ¡ corriendo
make test

# 6. Ver URLs de los servicios
make urls
```

### ğŸ“¦ Servicios Docker Disponibles

Una vez ejecutado `make run`, tendrÃ¡s acceso a:

| Servicio | Puerto | URL | DescripciÃ³n |
|----------|--------|-----|-------------|
| **FastAPI** | 8000 | http://localhost:8000 | API REST con predicciones |
| **MLflow UI** | 5000 | http://localhost:5000 | Tracking de experimentos |
| **Frontend** | 8080 | http://localhost:8080 | Dashboard web completo |
| **Swagger Docs** | 8000 | http://localhost:8000/docs | DocumentaciÃ³n interactiva API |

### ğŸ› ï¸ Comandos Makefile Disponibles

```bash
# GestiÃ³n Principal
make help           # Mostrar todos los comandos disponibles
make build          # Construir todas las imÃ¡genes Docker
make up             # Iniciar todos los servicios (docker-compose up)
make down           # Detener todos los servicios (docker-compose down)
make restart        # Reiniciar todos los servicios
make clean          # Eliminar contenedores, redes y volÃºmenes

# Monitoreo y Logs
make logs           # Ver logs de todos los servicios en tiempo real
make logs-api       # Ver solo logs del backend (API + DVC)
make logs-mlflow    # Ver solo logs de MLflow
make logs-frontend  # Ver solo logs del frontend
make ps             # Ver estado de todos los contenedores

# Operaciones
make shell          # Abrir bash en el contenedor backend
make dvc-repro      # Ejecutar pipeline DVC dentro del contenedor
make test           # Verificar salud de todos los servicios (health check)
make urls           # Mostrar URLs de acceso a servicios

# Shortcuts
make run            # Alias de 'make up'
make stop           # Alias de 'make down'
make rebuild        # Alias de 'make clean build up'
```

### ğŸ”§ Proceso de InicializaciÃ³n con Docker Compose

Cuando ejecutas `make up`, Docker Compose orquesta automÃ¡ticamente:

**1. Backend Container (puerto 8000)**
   - Instala dependencias Python desde `requirements.txt`
   - Ejecuta `dvc repro` para correr todo el pipeline de ML
   - Inicia FastAPI con `uvicorn` en modo reload

**2. MLflow Container (puerto 5000)**
   - Comparte el volumen `mlruns/` con el backend
   - Inicia MLflow UI para visualizar experimentos
   - Disponible inmediatamente para tracking

**3. Frontend Container (puerto 8080)**
   - Instala dependencias Node.js con `npm install`
   - Inicia Vite dev server con hot-reload
   - Depende de que backend estÃ© saludable antes de iniciar

Todos los servicios tienen **health checks** automÃ¡ticos y se reinician si fallan.

### ğŸ¯ Uso TÃ­pico con Docker

```bash
# Desarrollo rÃ¡pido
make build && make run && make logs

# Verificar servicios
make test
make urls

# Ejecutar pipeline manualmente
make dvc-repro

# Debug
make shell
make api-logs

# Limpieza completa
make clean
```

---

## ğŸ’» OpciÃ³n 2: Setup Local (Desarrollo)

### Setup Manual Paso a Paso

```bash
# 1. Crear entorno virtual
python -m venv venv
source venv/bin/activate  # Linux/Mac
# o
venv\Scripts\activate     # Windows

# 2. Instalar dependencias Python
pip install -r requirements.txt

# 3. Ejecutar pipeline de entrenamiento (DVC)
dvc repro

# 4. Iniciar API en terminal 1
uvicorn api.main:app --reload --port 8000

# 5. Iniciar MLflow UI en terminal 2
mlflow ui --port 5000

# 6. Iniciar Frontend en terminal 3
cd front
npm install
npm run dev
```

### VerificaciÃ³n Local

```bash
# API Health Check
curl http://localhost:8000/health

# Swagger Docs
open http://localhost:8000/docs

# MLflow UI
open http://localhost:5000

# Frontend
open http://localhost:8082  # Vite dev server
```

---

## ğŸ—ï¸ Arquitectura Docker

### Docker Compose - Arquitectura Multi-Contenedor

El proyecto utiliza **Docker Compose** con una arquitectura de 3 servicios independientes:

```yaml
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                   Docker Compose Network                     â”‚
â”‚                  (mlops-housing-network)                     â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                              â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”‚
â”‚  â”‚   Backend    â”‚  â”‚   MLflow     â”‚  â”‚   Frontend   â”‚     â”‚
â”‚  â”‚   Container  â”‚  â”‚   Container  â”‚  â”‚   Container  â”‚     â”‚
â”‚  â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤  â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤  â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤     â”‚
â”‚  â”‚ Python 3.11  â”‚  â”‚ Python 3.11  â”‚  â”‚ Node 20      â”‚     â”‚
â”‚  â”‚ DVC + FastAPIâ”‚  â”‚ MLflow UI    â”‚  â”‚ Vite Dev     â”‚     â”‚
â”‚  â”‚ Port: 8000   â”‚  â”‚ Port: 5000   â”‚  â”‚ Port: 8080   â”‚     â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â”‚
â”‚         â”‚                 â”‚                  â”‚              â”‚
â”‚         â–¼                 â–¼                  â–¼              â”‚
â”‚   ./data/           ./mlruns/          ./front/            â”‚
â”‚   ./models/                                                 â”‚
â”‚   ./mlruns/                                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Servicios Docker

| Servicio | Imagen | Puerto | FunciÃ³n | Comando Inicial |
|----------|--------|--------|---------|-----------------|
| **backend** | Python 3.11-slim | 8000 | DVC + FastAPI | `dvc repro â†’ uvicorn` |
| **mlflow** | Python 3.11-slim | 5000 | MLflow UI | `mlflow ui` |
| **frontend** | Node 20-alpine | 8080 | Vite Dev Server | `npm install â†’ npm run dev` |

### VolÃºmenes Persistentes

Los siguientes directorios se montan como volÃºmenes para persistir datos:

```bash
# Backend
-v ./data:/app/data         # Datos del pipeline
-v ./models:/app/models     # Modelos entrenados
-v ./mlruns:/app/mlruns     # Experimentos MLflow

# MLflow
-v ./mlruns:/app/mlruns     # Experimentos compartidos

# Frontend
-v ./front:/app             # CÃ³digo fuente con hot reload
```

### Archivos de ConfiguraciÃ³n

```
docker-compose.yml       # OrquestaciÃ³n de servicios
Dockerfile               # Imagen Python backend
.dockerignore           # Exclusiones de build
Makefile                # Comandos de gestiÃ³n simplificados
```

### CaracterÃ­sticas

âœ… **Aislamiento**: Cada servicio en su propio contenedor  
âœ… **Independencia**: Los servicios pueden reiniciarse sin afectar a otros  
âœ… **Hot Reload**: Frontend y API con recarga automÃ¡tica en desarrollo  
âœ… **Persistencia**: Datos compartidos mediante volÃºmenes  
âœ… **Health Checks**: Monitoreo automÃ¡tico de estado de servicios  
âœ… **Network Aislado**: Red privada para comunicaciÃ³n entre servicios  

---

## ğŸ“‚ Estructura del Proyecto

```
meli-mlops-mateo-restrepo/
â”œâ”€â”€ api/                          # API REST
â”‚   â”œâ”€â”€ main.py                   # FastAPI application
â”‚   â”œâ”€â”€ monitoring.py             # Monitoring & drift detection
â”‚   â””â”€â”€ security.py               # Authentication & rate limiting
â”‚
â”œâ”€â”€ src/                          # Pipeline de ML
â”‚   â”œâ”€â”€ data_ingestion.py         # Descarga de datos (Kaggle)
â”‚   â”œâ”€â”€ data_preparation.py       # Limpieza, split, scaling
â”‚   â”œâ”€â”€ model_train.py            # Entrenamiento (3 experimentos XGBoost)
â”‚   â”œâ”€â”€ model_register.py         # MLflow Model Registry (opcional)
â”‚   â””â”€â”€ config.py                 # ConfiguraciÃ³n centralizada
â”‚
â”œâ”€â”€ docker/                       # ğŸ³ ConfiguraciÃ³n Docker
â”‚   â”œâ”€â”€ nginx.conf                # Nginx reverse proxy
â”‚   â””â”€â”€ supervisord.conf          # Process manager config
â”‚
â”œâ”€â”€ front/                        # ğŸŒ Frontend React
â”‚   â”œâ”€â”€ src/                      # CÃ³digo fuente React
â”‚   â”œâ”€â”€ public/                   # Assets estÃ¡ticos
â”‚   â””â”€â”€ package.json              # Dependencias Node.js
â”‚
â”œâ”€â”€ tests/                        # Tests comprehensivos
â”‚   â”œâ”€â”€ test_api.py               # Tests de API (endpoints, security)
â”‚   â”œâ”€â”€ test_pipeline.py          # Tests de pipeline (data, training)
â”‚   â”œâ”€â”€ test_model.py             # Tests de modelo (quality, performance)
â”‚   â””â”€â”€ conftest.py               # Fixtures de pytest
â”‚
â”œâ”€â”€ data/                         # Datos versionados con DVC
â”‚   â”œâ”€â”€ raw/                      # Datos originales
â”‚   â”œâ”€â”€ processed/                # Datos preprocesados
â”‚   â”œâ”€â”€ predictions/              # Predicciones guardadas
â”‚   â””â”€â”€ reports/                  # Reportes EDA
â”‚
â”œâ”€â”€ models/                       # Modelos en producciÃ³n
â”‚   â””â”€â”€ production/latest/        # Ãšltimo modelo productizado
â”‚       â”œâ”€â”€ model.pkl
â”‚       â”œâ”€â”€ scaler.pkl
â”‚       â””â”€â”€ metadata.json
â”‚
â”œâ”€â”€ mlruns/                       # MLflow tracking (local)
â”‚   â””â”€â”€ <experiment_id>/          # Experimentos, runs, artifacts
â”‚
â”œâ”€â”€ .github/workflows/            # CI/CD con GitHub Actions
â”‚   â”œâ”€â”€ ml-pipeline.yml           # Pipeline principal (train + test + deploy)
â”‚   â”œâ”€â”€ api-tests.yml             # Tests de API
â”‚   â””â”€â”€ scheduled-retrain.yml     # Reentrenamiento automÃ¡tico semanal
â”‚
â”œâ”€â”€ dvc.yaml                      # Pipeline DVC (reproducibilidad)
â”œâ”€â”€ params.yaml                   # HiperparÃ¡metros y configuraciÃ³n
â”œâ”€â”€ docker-compose.yml            # OrquestaciÃ³n de servicios
â”œâ”€â”€ Dockerfile                    # Imagen Docker para API
â”œâ”€â”€ Makefile                      # Comandos de desarrollo
â”œâ”€â”€ requirements.txt              # Dependencias Python
â””â”€â”€ README.md                     # Este archivo
```

---

## ğŸ”¬ Pipeline de Entrenamiento

El pipeline estÃ¡ implementado con **DVC** para reproducibilidad completa:

### Etapa 1: Data Ingestion (`src/data_ingestion.py`)

- Descarga dataset Boston Housing desde Kaggle
- Genera reporte EDA automÃ¡tico con `ydata-profiling`
- Output: `data/raw/HousingData.csv`

### Etapa 2: Data Preparation (`src/data_preparation.py`)

- **Limpieza**: Manejo de valores nulos (mediana/moda)
- **Split**: Train/Test (80/20) con seed fijo
- **Scaling**: StandardScaler (importante: guarda scaler puro, no dict)
- **Outputs**: 
  - `data/processed/{train,test,X_train,X_test,y_train,y_test}.csv`
  - `models/production/latest/scaler.pkl` (para API)

### Etapa 3: Model Training (`src/model_train.py`)

**3 Experimentos XGBoost con MLflow Autologging:**

1. **Hyperparameter Tuning** (todas las features)
   - RandomizedSearchCV con 50 iteraciones
   - 5-fold cross-validation
   
2. **Important Features** (selecciÃ³n con SHAP)
   - Selecciona top features (percentil 20)
   - HyperparÃ¡metros default
   
3. **Tuning on Selected Features**
   - RandomizedSearchCV en features seleccionadas
   - Mejor balance performance/complejidad

**Artifacts generados automÃ¡ticamente:**
- Feature importance (weight, gain, cover)
- SHAP values y plots
- Residuals plot
- Predictions vs Actuals
- Model signature (MLflow)

**Output:** Mejor modelo exportado a `models/production/latest/`

### EjecuciÃ³n del Pipeline

```bash
# Ejecutar pipeline completo
dvc repro

# Ejecutar stages especÃ­ficos
dvc repro data_preparation
dvc repro model_train

# Ver DAG del pipeline
dvc dag
```

---

## ğŸŒ API REST

FastAPI-based REST API con validaciÃ³n automÃ¡tica, documentaciÃ³n Swagger y monitoreo.

### Endpoints Principales

#### `POST /predict` - PredicciÃ³n Individual

Realiza predicciÃ³n para una vivienda.

**Request:**
```json
{
  "CRIM": 0.00632,
  "NOX": 0.538,
  "RM": 6.575,
  "AGE": 65.2,
  "DIS": 4.09,
  "RAD": 1.0,
  "TAX": 296.0,
  "PTRATIO": 15.3,
  "B": 396.90,
  "LSTAT": 4.98
}
```

**Response:**
```json
{
  "prediction": 24.5,
  "model_name": "boston_housing_xgboost",
  "model_version": "1.0",
  "inference_time": 15.2,
  "features_used": ["CRIM", "NOX", "RM", ...]
}
```

**Con autenticaciÃ³n (producciÃ³n):**
```bash
curl -X POST http://localhost:8000/predict \
  -H "Content-Type: application/json" \
  -H "X-API-Key: demo-key-123" \
  -d '{"CRIM": 0.00632, "NOX": 0.538, ...}'
```

#### `POST /predict/batch` - PredicciÃ³n en Batch

MÃºltiples predicciones en una sola request.

**Request:**
```json
{
  "instances": [
    {"CRIM": 0.00632, "NOX": 0.538, ...},
    {"CRIM": 0.02731, "NOX": 0.469, ...}
  ]
}
```

#### `GET /health` - Health Check

VerificaciÃ³n del estado del servicio y modelos cargados.

#### `GET /metrics` - MÃ©tricas de Performance

EstadÃ­sticas de uso, latencia y predicciones.

#### `GET /drift` - DetecciÃ³n de Data Drift

Compara distribuciÃ³n actual vs baseline para detectar drift.

### DocumentaciÃ³n Interactiva

- **Swagger UI**: http://localhost:8000/docs
- **ReDoc**: http://localhost:8000/redoc

### Seguridad Implementada

1. **API Key Authentication**: Header `X-API-Key`
2. **Rate Limiting**: 100 requests/min por API key
3. **Input Validation**: Pydantic schemas con rangos vÃ¡lidos
4. **CORS**: Configurado para desarrollo (ajustar en producciÃ³n)

---

## ğŸ“Š Monitoreo

Sistema de monitoreo completo implementado en `api/monitoring.py`:

### MÃ©tricas Rastreadas

1. **Performance Metrics**
   - Total de predicciones
   - Uptime del servicio
   - Predicciones por hora

2. **Latency Metrics**
   - Tiempo promedio de inferencia
   - Percentiles: p50, p95, p99
   - Tiempo mÃ¡ximo de inferencia

3. **Prediction Statistics**
   - Media, mediana, std de predicciones
   - Min/max values
   - DistribuciÃ³n de predicciones

4. **Data Drift Detection**
   - ComparaciÃ³n vs baseline (mean Â± 2Ïƒ)
   - Drift score por feature
   - Alertas automÃ¡ticas

### Configurar Baseline para Drift Detection

```python
from api.monitoring import monitor

# Configurar baseline con datos histÃ³ricos
historical_predictions = [20.5, 22.3, 19.8, ...]
historical_features = {
    'CRIM': [0.1, 0.2, ...],
    'RM': [6.0, 6.5, ...]
}

monitor.set_baseline(historical_predictions, historical_features)
```

---

## ğŸ³ Despliegue

### Docker

```bash
# Build imagen
docker build -t housing-api:latest .

# Run container
docker run -p 8000:8000 housing-api:latest
```

### Docker Compose (Stack Completo)

```bash
# Iniciar servicios (API + MLflow UI)
docker-compose up -d

# Ver logs
docker-compose logs -f api

# Detener servicios
docker-compose down
```

**Servicios disponibles:**
- API: http://localhost:8000
- MLflow UI: http://localhost:5000
- Docs: http://localhost:8000/docs

### GitHub Actions CI/CD

3 workflows automatizados:

1. **`ml-pipeline.yml`** (on push to main)
   - Setup Python environment
   - Run tests
   - Execute DVC pipeline
   - Build Docker image
   - Deploy to production

2. **`api-tests.yml`** (on PR)
   - Unit tests
   - Integration tests
   - API tests

3. **`scheduled-retrain.yml`** (cron: weekly)
   - Reentrenamiento automÃ¡tico
   - EvaluaciÃ³n de modelo nuevo
   - Deploy si mejora performance

---

## ğŸ§  Decisiones TÃ©cnicas

### 1. Stack TecnolÃ³gico

**Â¿Por quÃ© estas tecnologÃ­as?**

| Herramienta | JustificaciÃ³n |
|-------------|---------------|
| **XGBoost** | Mejor performance para datos tabulares, interpretable con SHAP |
| **FastAPI** | Async by default, validaciÃ³n automÃ¡tica (Pydantic), docs autogeneradas |
| **MLflow** | Open-source, tracking completo, Model Registry, serving capabilities |
| **DVC** | Versionado de datos/modelos, reproducibilidad, integraciÃ³n Git |
| **Docker** | Portabilidad, reproducibilidad del entorno, fÃ¡cil deployment |
| **GitHub Actions** | CI/CD nativo de GitHub, gratuito, gran ecosistema de actions |

### 2. Arquitectura de Pipeline

**SeparaciÃ³n clara de responsabilidades:**

- `data_preparation.py` â†’ **ÃšNICO responsable del scaler**
  - Guarda `scaler.pkl` directamente en `models/production/latest/`
  - Evita duplicaciÃ³n y mantiene coherencia
  
- `model_train.py` â†’ **SOLO entrena y exporta modelo**
  - No duplica el scaler
  - Verifica que scaler exista antes de exportar

**Beneficios:**
- No hay duplicaciÃ³n de lÃ³gica
- El scaler siempre estÃ¡ sincronizado con los datos
- Pipeline mÃ¡s eficiente (no re-calcula scaler)

### 3. MLflow Autologging vs Manual Logging

**Elegimos Autologging porque:**
- âœ… Logs automÃ¡ticos de hiperparÃ¡metros
- âœ… Captura model signature automÃ¡ticamente
- âœ… Guarda pip requirements
- âœ… Menos cÃ³digo, menos errores

**Lo que agregamos manualmente:**
- Feature importance plots
- SHAP values y waterfall plots
- Custom metrics (CV scores, test metrics)
- Metadata JSON para API

### 4. Scaler: Dict vs StandardScaler Puro

**Problema original:**
```python
# âŒ ANTES: Guardaba dict
joblib.dump({
    "escalador": StandardScaler(),
    "nombres_caracteristicas": [...],
    "nombre_objetivo": "MEDV"
}, "scaler.pkl")
```

**SoluciÃ³n:**
```python
# âœ… AHORA: Guarda StandardScaler puro
joblib.dump(prep.escalador, "models/production/latest/scaler.pkl")
```

**JustificaciÃ³n:**
- API necesita `.transform()` directamente
- MÃ¡s simple, menos overhead
- Metadata de features ya estÃ¡ en `metadata.json`

### 5. ValidaciÃ³n de Inputs (Pydantic)

**Features requeridas vs opcionales:**

- **Requeridas** (10): Las que el modelo usa â†’ `Field(...)`
- **Opcionales** (3): Las que el scaler necesita pero modelo no usa â†’ `Field(0.0)`

```python
class PredictionInput(BaseModel):
    # Requeridas por el modelo
    CRIM: float = Field(..., ge=0.0, le=100.0)
    RM: float = Field(..., ge=3.0, le=9.0)
    
    # Opcionales (para scaler)
    ZN: Optional[float] = Field(0.0, ge=0.0, le=100.0)
```

**Beneficios:**
- ValidaciÃ³n automÃ¡tica de rangos
- DocumentaciÃ³n autogenerada
- Mejor experiencia de usuario (errores claros)

### 6. Seguridad: API Keys + Rate Limiting

**ImplementaciÃ³n simple pero efectiva:**

- API Keys en variable de entorno (configurable)
- Rate limiter in-memory (100 req/min)
- Para producciÃ³n escalable â†’ usar Redis

**Alternativas consideradas:**
- OAuth2: Sobrekill para este caso
- JWT: MÃ¡s complejo sin beneficio claro
- Sin auth: âŒ No aceptable en producciÃ³n

### 7. Monitoreo: In-Memory vs Persistente

**SoluciÃ³n actual: In-memory (deque)**
- âœ… RÃ¡pido, sin overhead
- âœ… Suficiente para MVP
- âŒ Se pierde al restart

**Para producciÃ³n:**
- Usar Prometheus + Grafana
- Persistir mÃ©tricas en TimeSeries DB
- Alerting con thresholds configurables

---

## ğŸ§ª Testing

Suite completa de tests con pytest:

```bash
# Todos los tests
pytest

# Con coverage
pytest --cov=src --cov=api --cov-report=html

# Solo tests rÃ¡pidos
pytest -m "not slow"

# Solo tests de API
pytest tests/test_api.py -v

# Solo tests de pipeline
pytest tests/test_pipeline.py -v
```

### CategorÃ­as de Tests

1. **Unit Tests** (`test_pipeline.py`)
   - Data cleaning
   - Train/test splitting
   - Scaler fitting/transforming

2. **Integration Tests** (`test_api.py`)
   - Endpoints (health, predict, batch)
   - Input validation
   - Error handling
   - Performance (latency)

3. **Model Quality Tests** (`test_model.py`)
   - Performance thresholds (RMSE < 5.0, RÂ² > 0.7)
   - Feature importance
   - Model invariants (mÃ¡s rooms â†’ mayor precio)
   - Scaler properties

---

## ğŸ”® Mejoras Futuras

### Corto Plazo (1-2 sprints)

1. **Data Quality Checks**
   - Implementar Great Expectations
   - ValidaciÃ³n automÃ¡tica de datos incoming
   - Alertas en data quality issues

2. **A/B Testing**
   - Endpoint para mÃºltiples modelos
   - Traffic splitting configurable
   - ComparaciÃ³n de performance

3. **Explicabilidad**
   - Endpoint `/explain` con SHAP values
   - Feature contribution por predicciÃ³n

### Mediano Plazo (3-6 meses)

4. **Model Registry Avanzado**
   - Staging â†’ Production automÃ¡tico
   - Rollback capabilities
   - Modelo champion/challenger

5. **Monitoring Avanzado**
   - Prometheus + Grafana stack
   - Alerting basado en mÃ©tricas
   - Dashboards personalizados

6. **Reentrenamiento Inteligente**
   - Trigger basado en drift detection
   - Reentrenamiento con datos nuevos
   - EvaluaciÃ³n automÃ¡tica pre-deploy

### Largo Plazo (6+ meses)

7. **Kubernetes Deployment**
   - Helm charts para deployment
   - Autoscaling basado en carga
   - Multi-region deployment

8. **Feature Store**
   - CentralizaciÃ³n de features
   - Online/Offline serving
   - Feature lineage tracking

9. **AutoML Integration**
   - Hyperparameter optimization automÃ¡tico
   - Model selection automÃ¡tico
   - Feature engineering automÃ¡tico

---

## ğŸ¤– Uso de Herramientas AI

Este proyecto fue desarrollado con asistencia de herramientas de IA para maximizar productividad y calidad:

### GitHub Copilot

**Uso principal:**
- Autocompletado de cÃ³digo repetitivo (logging, docstrings)
- Sugerencias de tests basados en funciones existentes
- GeneraciÃ³n de schemas Pydantic

**Impacto:**
- âš¡ 40% mÃ¡s rÃ¡pido en escribir tests
- ğŸ“ DocumentaciÃ³n mÃ¡s consistente
- ğŸ› Menos bugs por typos

### ChatGPT / Claude

**Uso principal:**
- RevisiÃ³n de arquitectura y decisiones tÃ©cnicas
- OptimizaciÃ³n de prompts para documentaciÃ³n
- Debugging de issues complejos (ej: scaler dict problem)

**Ejemplo concreto:**
```
Problema: API fallaba con "dict has no attribute transform"
SoluciÃ³n con AI: IdentificÃ³ que scaler estaba guardado como dict
â†’ CambiÃ³ arquitectura para guardar StandardScaler puro
```

### Consideraciones Ã‰ticas

- âœ… Todo el cÃ³digo generado fue **revisado y validado**
- âœ… Se **entiende completamente** la lÃ³gica implementada
- âœ… Tests garantizan **correctitud** del cÃ³digo
- âœ… DocumentaciÃ³n refleja **decisiones conscientes**, no solo output de AI

---

## ğŸ“ Licencia

MIT License - ver [LICENSE](LICENSE) para detalles

---

## ğŸ‘¤ Autor

**Mateo Restrepo**
- GitHub: [@marestrepohi](https://github.com/marestrepohi)
- LinkedIn: [mateo-restrepo](https://linkedin.com/in/mateo-restrepo)

---

## ğŸ¯ Ejemplos de Uso Completo

### Ejemplo 1: Quick Start con Docker

```bash
# Clonar y construir
git clone https://github.com/marestrepohi/meli-mlops-mateo-restrepo.git
cd meli-mlops-mateo-restrepo
make build

# Ejecutar todos los servicios
make run

# Verificar que todo estÃ¡ funcionando
make test

# Ver logs en tiempo real
make logs
```

### Ejemplo 2: Hacer una PredicciÃ³n

```bash
# Usando curl
curl -X POST "http://localhost:8000/predict" \
  -H "Content-Type: application/json" \
  -d '{
    "CRIM": 0.00632,
    "NOX": 0.538,
    "RM": 6.575,
    "AGE": 65.2,
    "DIS": 4.09,
    "RAD": 1.0,
    "TAX": 296.0,
    "PTRATIO": 15.3,
    "B": 396.90,
    "LSTAT": 4.98
  }'

# Respuesta esperada:
# {
#   "prediction": 24.5,
#   "model_name": "02_important_features",
#   "model_version": "1.0.0",
#   "model_stage": "Production",
#   "inference_time": 12.3,
#   "features_used": ["CRIM", "NOX", "RM", ...]
# }
```

### Ejemplo 3: Entrenar Nuevo Modelo

```bash
# Ejecutar pipeline DVC dentro del contenedor
make dvc-repro

# O manual dentro del shell
make shell
> dvc repro
> exit

# Ver nuevos experimentos en MLflow
open http://localhost:5000
```

### Ejemplo 4: Monitorear Drift

```bash
# Ver estadÃ­sticas de predicciones
curl http://localhost:8000/monitoring/stats

# Detectar data drift
curl http://localhost:8000/monitoring/drift

# Ver dashboard de monitoreo
open http://localhost:8000/monitoring/dashboard
```

### Ejemplo 5: Desarrollo Local

```bash
# Setup Python environment
python -m venv venv
source venv/bin/activate
pip install -r requirements.txt

# Ejecutar pipeline
dvc repro

# Terminal 1: API
uvicorn api.main:app --reload --port 8000

# Terminal 2: MLflow UI
mlflow ui --port 5000

# Terminal 3: Frontend
cd front && npm install && npm run dev
```

---

## ğŸ“Š Resumen de Comandos Make

| Comando | DescripciÃ³n | Uso |
|---------|-------------|-----|
| `make help` | Muestra ayuda completa | Siempre empieza aquÃ­ |
| `make build` | Construye imagen Docker | Primera vez o despuÃ©s de cambios |
| `make run` | Inicia todos los servicios | Deployment completo |
| `make stop` | Detiene el contenedor | Cuando termines |
| `make restart` | Reinicia servicios | DespuÃ©s de cambios de config |
| `make logs` | Ver logs en vivo | Debugging |
| `make shell` | Abrir bash en contenedor | Ejecutar comandos dentro |
| `make test` | Verificar servicios | Health check rÃ¡pido |
| `make dvc-repro` | Ejecutar pipeline ML | Reentrenar modelo |
| `make clean` | Limpieza completa | Empezar de cero |
| `make urls` | Mostrar URLs servicios | Ver puertos y endpoints |

---

## ğŸ™ Agradecimientos

- Dataset: Boston Housing (UCI Machine Learning Repository)
- MLflow Team por el excelente framework de tracking
- FastAPI team por la mejor experiencia de developer
- Comunidad open-source de Python ML
- Docker & Supervisor por simplificar el deployment

---

## ğŸ“š Referencias

- [MLflow Documentation](https://mlflow.org/docs/latest/index.html)
- [FastAPI Best Practices](https://fastapi.tiangolo.com/tutorial/)
- [DVC Documentation](https://dvc.org/doc)
- [XGBoost Documentation](https://xgboost.readthedocs.io/)
- [MLOps Principles](https://ml-ops.org/)

---

**â­ Si este proyecto te fue Ãºtil, considera darle una estrella en GitHub!**
