# ğŸ  PredicciÃ³n de Precios de Viviendas - Sistema MLOps Completo

[![Pipeline CI/CD](https://img.shields.io/badge/CI%2FCD-GitHub%20Actions-blue)](https://github.com/marestrepohi/meli-mlops-mateo-restrepo/actions)
[![Python 3.11+](https://img.shields.io/badge/python-3.11+-blue.svg)](https://www.python.org/downloads/)
[![FastAPI](https://img.shields.io/badge/FastAPI-0.104+-green.svg)](https://fastapi.tiangolo.com/)
[![MLflow](https://img.shields.io/badge/MLflow-2.8+-orange.svg)](https://mlflow.org/)
[![Docker](https://img.shields.io/badge/Docker-Compose-blue.svg)](https://docs.docker.com/compose/)
[![ColaboraciÃ³n](https://img.shields.io/badge/Creado%20con-GitHub%20Copilot-ffd700.svg)](https://github.com/features/copilot)
[![Licencia](https://img.shields.io/badge/licencia-MIT-blue.svg)](LICENSE)

---
## ğŸ‘¤ Autor

**Mateo Restrepo**
- GitHub: [@marestrepohi](https://github.com/marestrepohi)
- LinkedIn: [mateo-restrepo](https://www.linkedin.com/in/mateorestrepohiguita-datascientist/)
---



<div align="center">

## ğŸ¥ Video Demo del Proyecto

[![Ver Video Demo](https://img.shields.io/badge/â–¶ï¸-Ver_Video_Completo-red?style=for-the-badge&logo=youtube)](https://drive.google.com/file/d/1MZXWTC2SF8O0-vJjvufFEhiZZ7-SA7KM/view?usp=sharing)

### ğŸ¯ Dashboard MLOps Completo
<img src="meli_mlops.png" alt="Dashboard MLOps" width="800"/>

### ğŸ”µ API REST con FastAPI
<img src="meli_api.png" alt="API FastAPI" width="800"/>

### ğŸ“Š MLflow Tracking UI
<img src="meli_mlflow.png" alt="MLflow UI" width="800"/>

</div>

---

> ğŸ¤– **Sistema completo y producciÃ³n-ready de MLOps** para predicciÃ³n de precios de viviendas. 
> SoluciÃ³n agnÃ³stica a la nube con tecnologÃ­as open-source, pipeline reproducible, API REST, monitoreo continuo y CI/CD automatizado. 
> **Este proyecto fue co-creado con GitHub Copilot** integrando tÃ©cnicas modernas de IA en todo el ciclo de desarrollo.

---

## ğŸ“‹ Objetivo del Proyecto

Este proyecto implementa una **soluciÃ³n end-to-end de Machine Learning Operations (MLOps)** para predecir precios de viviendas utilizando el dataset Boston Housing. 

### ğŸ¯ Objetivos Clave

1. âœ… **Reproducibilidad Total**: Pipeline versionado con DVC y Git
2. âœ… **AgnÃ³stico a Cloud**: Solo herramientas open-source y self-hosted
3. âœ… **Monitoreo en Tiempo Real**: Tracking de performance, latencia y data drift
4. âœ… **Escalabilidad**: Arquitectura containerizada lista para Kubernetes
5. âœ… **Mantenibilidad**: CÃ³digo modular, documentado y testeado
6. âœ… **AutomatizaciÃ³n**: CI/CD completo con GitHub Actions
7. âœ… **Interferencia Ã“ptima**: API REST con validaciÃ³n y seguridad


## ï¿½ğŸš€ Inicio RÃ¡pido - 2 Opciones

### OpciÃ³n 1ï¸âƒ£: Con Docker - Makefile (RECOMENDADO - MÃ¡s FÃ¡cil)

**Requisitos:**
- âœ… Docker y linux instalado (descargar desde https://www.docker.com/products/docker-desktop)
- âœ… Git

**Pasos:**

```bash
# 1. Clonar el repositorio
git clone https://github.com/marestrepohi/meli-mlops-mateo-restrepo.git
cd meli-mlops-mateo-restrepo


# 1. Iniciar todos los servicios (DVC Pipeline + API + MLflow + Frontend)

make start          -  Construir + Iniciar todos los servicios (RECOMENDADO)

## Otros comandos
make build          - Construir todas las imÃ¡genes Docker
make up             - Iniciar todos los servicios (API, MLflow, Frontend)
make down           - Detener y remover todos los contenedores
make restart        - Reiniciar todos los servicios


```

**Â¿QuÃ© sucede automÃ¡ticamente?**
```
â”œâ”€ 1. Pipeline DVC se ejecuta (descarga datos, prepara, entrena modelo)
â”œâ”€ 2. Mejor modelo se exporta a models/production/latest/
â”œâ”€ 3. MLflow UI se inicia en puerto 5000
â”œâ”€ 4. FastAPI inicia en puerto 8000
â””â”€ 5. Frontend Vite inicia en puerto 8080
```

---

### OpciÃ³n 2ï¸âƒ£: Pasos Manuales (Setup Local)

**Requisitos:**
- âœ… Python 3.11+ instalado
- âœ… Git

**Pasos:**

```bash
# 1. Clonar repositorio
git clone https://github.com/marestrepohi/meli-mlops-mateo-restrepo.git
cd meli-mlops-mateo-restrepo
cp .env.example .env

# 2. Crear entorno virtual
python3 -m venv venv
source venv/bin/activate           # En Mac/Linux


# 3. Instalar dependencias Python
pip install -r requirements.txt

# 4. Ejecutar pipeline DVC (data + training)
dvc init               # Solo la primera vez
dvc repro

# 5. En terminal 1: Iniciar API
uvicorn api.main:app --reload --port 8000

# 6. En terminal 2: Iniciar MLflow UI
mlflow ui --port 5000

# 8. En terminal 3: Iniciar Frontend
cd front && npm install && npm run dev
```

---

## ğŸ“Š Servicios Disponibles

| Servicio | Puerto | URL | DescripciÃ³n |
|----------|--------|-----|-------------|
| **API (FastAPI)** | 8000 | http://localhost:8000 | REST API con predicciones en tiempo real |
| **Swagger Docs** | 8000 | http://localhost:8000/docs | DocumentaciÃ³n interactiva |
| **MLflow UI** | 5000 | http://localhost:5000 | Tracking de experimentos y modelos |
| **Frontend** | 8080 | http://localhost:8080 o http://localhost:8082 | Dashboard web interactivo |

---
## ğŸ§ª Testear la API

### Test 1: Health Check (Verificar que API estÃ¡ activa)

```bash
curl http://localhost:8000/health
```

**Respuesta esperada:**
```json
{
  "status": "healthy",
  "model_loaded": true,
  "scaler_loaded": true,
  "model_name": "boston_housing_xgboost",
  "model_version": "1.0",
  "total_predictions": 0
}
```

---

### Test 2: PredicciÃ³n Individual (Puerto 8000)

**Ejemplo: Predecir precio de una vivienda en Boston**

```bash
curl -X POST http://localhost:8000/predict \
  -H "Content-Type: application/json" \
  -d '{
    "CRIM": 0.00632,
    "ZN": 18.0,
    "INDUS": 2.31,
    "CHAS": 0.0,
    "NOX": 0.538,
    "RM": 6.575,
    "AGE": 65.2,
    "DIS": 4.09,
    "RAD": 1.0,
    "TAX": 296.0,
    "PTRATIO": 15.3,
    "B": 396.90,
    "LSTAT": 4.98
  }'
```

**Respuesta esperada:**
```json
{
  "prediction": 24.5,
  "model_name": "boston_housing_xgboost",
  "model_version": "v1.0",
  "model_stage": "Production",
  "inference_time": 12.34,
  "features_used": ["CRIM", "NOX", "RM", "AGE", "DIS", "RAD", "TAX", "PTRATIO", "B", "LSTAT"]
}
```

---

### Test 3: Predicciones en Batch

```bash
curl -X POST http://localhost:8000/predict/batch \
  -H "Content-Type: application/json" \
  -d '{
    "data": [
      {"CRIM": 0.00632, "NOX": 0.538, "RM": 6.575, "AGE": 65.2, "DIS": 4.09, "RAD": 1, "TAX": 296, "PTRATIO": 15.3, "B": 396.9, "LSTAT": 4.98},
      {"CRIM": 0.02731, "NOX": 0.469, "RM": 6.421, "AGE": 78.9, "DIS": 4.9671, "RAD": 2, "TAX": 242, "PTRATIO": 17.8, "B": 396.9, "LSTAT": 9.14}
    ]
  }'
```

**Respuesta esperada:**
```json
{
  "predictions": [
    {
      "index": 0,
      "prediction": 24.5,
      "inference_time_ms": 8.23
    },
    {
      "index": 1,
      "prediction": 21.8,
      "inference_time_ms": 7.45
    }
  ],
  "count": 2,
  "model_version": "v1.0",
  "total_inference_time": 15.68,
  "avg_inference_time": 7.84
}
```


## ğŸ”„ Flujo del Proyecto 

### Fase 1ï¸âƒ£: ExperimentaciÃ³n y ExploraciÃ³n (Notebooks)

**Archivos:** 
- `notebooks/data_extract_eda.ipynb` - AnÃ¡lisis Exploratorio de Datos
- `notebooks/model_train.ipynb` - ExperimentaciÃ³n con modelos

En esta fase inicial, se realiza:

```
1. Descargar datos de Kaggle (Boston Housing)
2. AnÃ¡lisis Exploratorio de Datos (EDA):
   - Distribuciones de variables
   - CorrelaciÃ³n de features
   - DetecciÃ³n de outliers
3. GeneraciÃ³n de reportes automatizados con ydata-profiling
4. ExperimentaciÃ³n con diferentes modelos y hiperparÃ¡metros
5. ValidaciÃ³n de resultados
```

**Salida:** 
- Reportes en `data/reports/eda_data.json`
- Insights sobre variables mÃ¡s importantes
- Decisiones de modelo para pipeline

---

### Fase 2ï¸âƒ£: Pipeline DVC (Reproducibilidad)

**Archivos:** `dvc.yaml`, `params.yaml`, `src/*.py`

Basado en los aprendizajes de la experimentaciÃ³n, se creÃ³ un **pipeline automatizado** con 4 etapas:

#### ğŸ“¥ Etapa 1: Data Ingestion (`src/data_ingestion.py`)
```bash
- Descarga datos de Kaggle API
- Genera reporte EDA automÃ¡tico
- Output: data/raw/HousingData.csv
```

#### ğŸ§¹ Etapa 2: Data Preparation (`src/data_preparation.py`)
```bash
- Limpieza de valores nulos (mediana/moda)
- Split train/test (80/20 con seed=42)
- StandardScaler para normalizaciÃ³n
- Output: data/processed/*.csv + models/production/latest/scaler.pkl
```

#### ğŸ¤– Etapa 3: Model Training (`src/model_train.py`)
```bash
Ejecuta 3 EXPERIMENTOS XGBoost con MLflow:

âœ… Experimento 1 - Hyperparameter Tuning (Todas las 13 features)
   â”œâ”€ RandomizedSearchCV con 50 iteraciones
   â”œâ”€ 5-fold cross-validation

âœ… Experimento 2 - Feature Importance con SHAP
   â”œâ”€ Selecciona top features (percentil 20)
   â”œâ”€ ~10 features mÃ¡s importantes

âœ… Experimento 3 - Tuning en Features Seleccionadas â­ GANADOR
   â”œâ”€ HiperparÃ¡metros optimizados para features seleccionadas
   â”œâ”€ Balance entre performance y complejidad


ğŸ† El MEJOR modelo (Experimento 3) se exporta AUTOMÃTICAMENTE a:
   - models/production/latest/model.pkl
   - models/production/latest/scaler.pkl
   - models/production/latest/metadata.json
```

#### ğŸ“¦ Etapa 4: Model Registration (`src/model_register.py`)
```bash
- Lee metadata del mejor modelo (generada por model_train.py)
- Registra automÃ¡ticamente en MLflow Model Registry
- Transiciona a stage "Production"
- Agrega tags y documentaciÃ³n
- Archiva versiones antiguas
```

**EjecuciÃ³n del pipeline:**

El pipeline estÃ¡ implementado con **DVC** para reproducibilidad completa:

```bash
dvc repro                    # Ejecuta TODO el pipeline
dvc dag                      # Visualiza DAG del pipeline
make dvc-repro              # Ejecuta desde Make
```

---

### Fase 3ï¸âƒ£: API REST para ProducciÃ³n (FastAPI)

**Archivo:** `api/main.py`

Una vez el modelo estÃ¡ entrenado y registrado, se **consume automÃ¡ticamente** en la API:

#### ğŸ”µ Endpoints Principales:

```bash
âœ… Health Check
GET /health
â†’ Verifica que el modelo estÃ¡ cargado

âœ… PredicciÃ³n Individual  
POST /predict
{
  "CRIM": 0.00632,
  "NOX": 0.538,
  "RM": 6.575,
  "AGE": 65.2,
  "DIS": 4.09,
  "RAD": 1.0,
  "TAX": 296.0,
  "PTRATIO": 15.3,
  "B": 396.90,
  "LSTAT": 4.98
}
â†’ Retorna predicciÃ³n + metadata

âœ… Predicciones en Batch
POST /predict/batch
{"data": [... mÃºltiples registros ...]}
â†’ Procesa varios registros eficientemente

âœ… MÃ©tricas de Monitoreo
GET /metrics
â†’ Total predicciones, latencia, uptime

âœ… DetecciÃ³n de Drift
GET /monitoring/drift
â†’ Compara con baseline para detectar cambios

âœ… Dashboard de Monitoreo
GET /monitoring/dashboard
â†’ HTML interactivo con mÃ©tricas en tiempo real
```


### Fase 4ï¸âƒ£: Monitoreo Continuo

**Archivo:** `api/monitoring.py`

Tracking automÃ¡tico de predicciones en producciÃ³n:

```bash
âœ… MÃ©tricas capturadas:
   - Total de predicciones
   - Tiempo de inferencia (p50, p95, p99)
   - DistribuciÃ³n de predicciones
   - DetecciÃ³n de data drift

âœ… Baselines:
   - Se pueden configurar manualmente
   - Detecta cambios en distribuciÃ³n
   - Alerta si hay drift significativo
```

---

## ğŸ“Š Monitoreo

Sistema de monitoreo completo implementado en `api/monitoring.py`:

### MÃ©tricas Rastreadas

1. **Performance Metrics**
   - Total de predicciones
   - Uptime del servicio
   - Predicciones por hora

2. **Latency Metrics**
   - Tiempo promedio de inferencia
   - Percentiles: p50, p95, p99
   - Tiempo mÃ¡ximo de inferencia

3. **Prediction Statistics**
   - Media, mediana, std de predicciones
   - Min/max values
   - DistribuciÃ³n de predicciones

4. **Data Drift Detection**
   - ComparaciÃ³n vs baseline (mean Â± 2Ïƒ)
   - Drift score por feature
   - Alertas automÃ¡ticas

### Configurar Baseline para Drift Detection

```python
from api.monitoring import monitor

# Configurar baseline con datos histÃ³ricos
historical_predictions = [20.5, 22.3, 19.8, ...]
historical_features = {
    'CRIM': [0.1, 0.2, ...],
    'RM': [6.0, 6.5, ...]
}

monitor.set_baseline(historical_predictions, historical_features)
```

---

### Fase 5ï¸âƒ£: Frontend Interactivo

**Carpeta:** `front/`

Interfaz web moderna con React + Vite:

```bash
âœ… Formulario para hacer predicciones
âœ… VisualizaciÃ³n de resultados en tiempo real
âœ… Dashboard de monitoreo con grÃ¡ficos
âœ… HistÃ³rico de predicciones
âœ… EstadÃ­sticas de performance
```

**Acceso:** http://localhost:8080

---

### Fase 6ï¸âƒ£: CI/CD Automatizado (GitHub Actions)

**Carpeta:** `.github/workflows/`

AutomatizaciÃ³n completa en cada push:

```bash
âœ… mlops-ci-cd.yml (Pipeline Principal)
   1. Code Quality: flake8 + pytest
   2. Train Model: Ejecuta DVC pipeline
   3. Build Docker: Construye imÃ¡genes
   4. Test API: Verifica todos los endpoints
   5. Deploy: Prepara para producciÃ³n

âœ… EjecuciÃ³n automÃ¡tica en:
   - Push a main/develop
   - Pull requests
   - Manual workflow_dispatch
```

---

## ğŸ“‚ Estructura Completa del Proyecto

```
meli-mlops-mateo-restrepo/
â”‚
â”œâ”€â”€ ğŸ““ NOTEBOOKS (ExperimentaciÃ³n y EDA)
â”‚   â”œâ”€â”€ notebooks/data_extract_eda.ipynb        # EDA interactivo del dataset
â”‚   â””â”€â”€ notebooks/model_train.ipynb             # ExperimentaciÃ³n con modelos
â”‚
â”œâ”€â”€ ğŸ”„ PIPELINE DVC (Reproducibilidad Total)
â”‚   â”œâ”€â”€ dvc.yaml                                # DefiniciÃ³n DAG del pipeline
â”‚   â”œâ”€â”€ params.yaml                             # HiperparÃ¡metros centralizados
â”‚   â””â”€â”€ src/
â”‚       â”œâ”€â”€ config.py                           # ConfiguraciÃ³n global
â”‚       â”œâ”€â”€ data_ingestion.py                   # Etapa 1: Descargar datos
â”‚       â”œâ”€â”€ data_preparation.py                 # Etapa 2: Limpieza + split + scale
â”‚       â”œâ”€â”€ model_train.py                      # Etapa 3: 3 experimentos XGBoost
â”‚       â””â”€â”€ model_register.py                   # Etapa 4: Registrar en MLflow
â”‚
â”œâ”€â”€ ğŸ”µ API REST (FastAPI con Monitoreo)
â”‚   â”œâ”€â”€ api/main.py                             # API principal + endpoints
â”‚   â”œâ”€â”€ api/monitoring.py                       # Monitoreo + drift detection
â”‚   â””â”€â”€ api/__init__.py
â”‚
â”œâ”€â”€ ğŸŒ FRONTEND (React + Vite + Tailwind)
â”‚   â”œâ”€â”€ front/src/
â”‚   â”‚   â”œâ”€â”€ components/                         # Componentes React
â”‚   â”‚   â”œâ”€â”€ pages/                              # PÃ¡ginas
â”‚   â”‚   â”œâ”€â”€ services/                           # Llamadas a API
â”‚   â”‚   â””â”€â”€ main.tsx
â”‚   â”œâ”€â”€ front/package.json
â”‚   â”œâ”€â”€ front/vite.config.ts
â”‚   â””â”€â”€ front/tailwind.config.ts
â”‚
â”œâ”€â”€ ğŸ³ DOCKER (ContenedorizaciÃ³n)
â”‚   â”œâ”€â”€ Dockerfile                              # Imagen Python backend
â”‚   â”œâ”€â”€ docker-compose.yml                      # OrquestaciÃ³n servicios
â”‚   â””â”€â”€ .dockerignore
â”‚
â”œâ”€â”€ ğŸ¤– CI/CD (GitHub Actions)
â”‚   â””â”€â”€ .github/workflows/
â”‚       â”œâ”€â”€ mlops-ci-cd.yml                     # Pipeline principal
â”‚       â””â”€â”€ mlops-pipeline-ultra-simple.yml.old # VersiÃ³n simplificada
â”‚
â”œâ”€â”€ ğŸ“Š DATOS (Versionados con DVC)
â”‚   â”œâ”€â”€ data/raw/                               # Datos originales de Kaggle
â”‚   â”œâ”€â”€ data/processed/                         # Datos preprocesados (train/test)
â”‚   â”œâ”€â”€ data/predictions/                       # HistÃ³rico de predicciones
â”‚   â””â”€â”€ data/reports/                           # Reportes EDA JSON/HTML
â”‚
â”œâ”€â”€ ğŸ¯ MODELOS (ProducciÃ³n Ready)
â”‚   â”œâ”€â”€ models/production/latest/
â”‚   â”‚   â”œâ”€â”€ model.pkl                           # Modelo XGBoost entrenado
â”‚   â”‚   â”œâ”€â”€ scaler.pkl                          # StandardScaler serializado
â”‚   â”‚   â””â”€â”€ metadata.json                       # Features, mÃ©tricas, timestamps
â”‚   â””â”€â”€ mlruns/                                 # MLflow experiment tracking
â”‚
â””â”€â”€ ğŸ“‹ CONFIGURACIÃ“N DEL PROYECTO
    â”œâ”€â”€ Makefile                                # Comandos Docker simplificados
    â”œâ”€â”€ requirements.txt                        # Dependencias Python
    â”œâ”€â”€ README.md                               
    â”œâ”€â”€ dvc.yaml
    â”œâ”€â”€ params.yaml
    â””â”€â”€ .env.example
 
---

## ğŸ—ï¸ Arquitectura Docker

### Docker Compose - Arquitectura Multi-Contenedor

El proyecto utiliza **Docker Compose** con una arquitectura de 3 servicios independientes:

```yaml
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                   Docker Compose Network                     â”‚
â”‚                  (mlops-housing-network)                     â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                              â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”‚
â”‚  â”‚   Backend    â”‚  â”‚   MLflow     â”‚  â”‚   Frontend   â”‚     â”‚
â”‚  â”‚   Container  â”‚  â”‚   Container  â”‚  â”‚   Container  â”‚     â”‚
â”‚  â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤  â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤  â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤     â”‚
â”‚  â”‚ Python 3.11  â”‚  â”‚ Python 3.11  â”‚  â”‚ Node 20      â”‚     â”‚
â”‚  â”‚ DVC + FastAPIâ”‚  â”‚ MLflow UI    â”‚  â”‚ Vite Dev     â”‚     â”‚
â”‚  â”‚ Port: 8000   â”‚  â”‚ Port: 5000   â”‚  â”‚ Port: 8080   â”‚     â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â”‚
â”‚         â”‚                 â”‚                  â”‚              â”‚
â”‚         â–¼                 â–¼                  â–¼              â”‚
â”‚   ./data/           ./mlruns/          ./front/            â”‚
â”‚   ./models/                                                 â”‚
â”‚   ./mlruns/                                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Servicios Docker

| Servicio | Imagen | Puerto | FunciÃ³n | Comando Inicial |
|----------|--------|--------|---------|-----------------|
| **backend** | Python 3.11-slim | 8000 | DVC + FastAPI | `dvc repro â†’ uvicorn` |
| **mlflow** | Python 3.11-slim | 5000 | MLflow UI | `mlflow ui` |
| **frontend** | Node 20-alpine | 8080 | Vite Dev Server | `npm install â†’ npm run dev` |

### Archivos de ConfiguraciÃ³n

```
docker-compose.yml       # OrquestaciÃ³n de servicios
Dockerfile               # Imagen Python backend
.dockerignore           # Exclusiones de build
Makefile                # Comandos de gestiÃ³n simplificados
```
---
## ğŸ¯ ConclusiÃ³n: PrÃ³ximos Pasos - IntegraciÃ³n de Plataforma de Monitoreo

Este proyecto establece las bases de una **arquitectura MLOps moderna y escalable**. Sin embargo, para llevarla a **producciÃ³n en empresas reales**, es fundamental integrar una **plataforma profesional de monitoreo y observabilidad**.

### ğŸš€ Roadmap de IntegraciÃ³n

#### **Actual (MVP - Fase Actual)**
```
âœ… Pipeline automatizado (DVC)
âœ… Model Registry (MLflow)
âœ… API REST (FastAPI)
âœ… Frontend bÃ¡sico (React/Vite)
âœ… Monitoreo local en memoria
```

### ğŸ“ Frontend Interactivo como Base

**El dashboard del frontend ya implementado incluye:**

```
ğŸ¨ Interfaz React moderna (puerto 8080)
â”œâ”€ ğŸ“Š Panel de mÃ©tricas en tiempo real
â”œâ”€ ğŸ” BÃºsqueda de predicciones por fecha/rango
â”œâ”€ ğŸ“ˆ GrÃ¡ficos de performance (RMSE, RÂ², MAE)
â”œâ”€ ğŸš¨ Alertas visuales de drift
â”œâ”€ ğŸ‘¥ Historial de predicciones
â””â”€ âš™ï¸ ConfiguraciÃ³n de baselines

ğŸ”— IntegraciÃ³n pendiente:
   â€¢ Conectar a base de datos de producciÃ³n
   â€¢ Mostrar mÃ©tricas reales desde plataforma de monitoreo
   â€¢ Alertas en UI basadas en thresholds configurables
   â€¢ Integrar herramientas de orquestaciÃ³n como Airflow
```



**Este proyecto fue completamente co-creado con GitHub Copilot**, aprovechando potentes capacidades de IA para:

âœ… Generar cÃ³digo de calidad producciÃ³n desde el inicio  
âœ… Sugerir mejores prÃ¡cticas de MLOps  
âœ… Documentar automÃ¡ticamente cada componente  
âœ… Optimizar configuraciones de pipeline  
âœ… Acelerar el tiempo de desarrollo de semanas a dÃ­as  
